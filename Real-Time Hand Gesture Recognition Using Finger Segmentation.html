<!--?xml version="1.0" encoding="utf-8"?-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <!-- AppResources meta begin -->
        <script type="text/javascript">var ncbi_startTime = new Date();</script>
        <!-- AppResources meta end -->
        
        <!-- TemplateResources meta begin -->
        <meta name="paf_template" content="">

        <!-- TemplateResources meta end -->
        
        <!-- Logger begin -->
        <meta name="ncbi_db" content="pmc"><meta name="ncbi_pdid" content="article"><meta name="ncbi_acc" content=""><meta name="ncbi_domain" content="tswj"><meta name="ncbi_report" content="record"><meta name="ncbi_type" content="fulltext"><meta name="ncbi_objectid" content=""><meta name="ncbi_pcid" content="/articles/PMC4099175/"><meta name="ncbi_app" content="pmc">
        <!-- Logger end -->
        
        <title>Real-Time Hand Gesture Recognition Using Finger Segmentation</title>
        
        <!-- AppResources external_resources begin -->
        <link rel="stylesheet" href="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/jig.css"><script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/jig.js"></script>

        <!-- AppResources external_resources end -->
        
        <!-- Page meta begin -->
        <meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE"><link rel="canonical" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/"><link rel="schema.DC" href="http://purl.org/DC/elements/1.0/"><meta name="citation_journal_title" content="The Scientific World Journal"><meta name="citation_title" content="Real-Time Hand Gesture Recognition Using Finger Segmentation"><meta name="citation_authors" content="Zhi-hua Chen, Jung-Tae Kim, Jianning Liang, Jing Zhang, Yu-Bo Yuan"><meta name="citation_date" content="2014"><meta name="citation_volume" content="2014"><meta name="citation_doi" content="10.1155/2014/267872"><meta name="citation_abstract_html_url" content="/pmc/articles/PMC4099175/?report=abstract"><meta name="citation_pmid" content="25054171"><meta name="DC.Title" content="Real-Time Hand Gesture Recognition Using Finger Segmentation"><meta name="DC.Type" content="Text"><meta name="DC.Publisher" content="Hindawi Limited"><meta name="DC.Contributor" content="Zhi-hua Chen"><meta name="DC.Contributor" content="Jung-Tae Kim"><meta name="DC.Contributor" content="Jianning Liang"><meta name="DC.Contributor" content="Jing Zhang"><meta name="DC.Contributor" content="Yu-Bo Yuan"><meta name="DC.Date" content="2014"><meta name="DC.Identifier" content="10.1155/2014/267872"><meta name="DC.Language" content="en"><meta property="og:title" content="Real-Time Hand Gesture Recognition Using Finger Segmentation"><meta property="og:type" content="article"><meta property="og:description" content="Hand gesture recognition is very significant for human-computer interaction. In this work, we present a novel real-time method for hand gesture recognition. In our framework, the hand region is extracted from the background with the background subtraction ..."><meta property="og:url" content="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/"><meta property="og:site_name" content="PubMed Central (PMC)"><meta property="og:image" content="https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ncbi"><link rel="stylesheet" href="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/pmc.css" type="text/css"><link rel="stylesheet" href="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/pmc_extras_prnt.css" type="text/css" media="print"><script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/common.js">//</script><script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/NcbiTagServer.js">//</script><meta name="citationexporter" content="backend:'/pmc/utils/ctxp/'"><script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/jquery.js">//</script><link rel="stylesheet" href="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/citationexporter.css" type="text/css"><script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/MathJax.js"></script><script type="text/javascript">window.name="mainwindow";</script><style type="text/css">.pmc-wm {background:transparent repeat-y top left;background-image:url(/corehtml/pmc/pmcgifs/wm-tswj.gif);background-size: auto, contain}</style><style type="text/css">.print-view{display:block}</style><style type="text/css">
        div.pmc_para_cit li.highlight,
        div.pmc_para_cit li.highlight .one_line_source
        { background: #E0E0E0; }
        a.bibr.highlight { background: #E0E0E0; } 
      </style><meta name="cited_in_systematic_reviews" content=""><link rel="alternate" type="application/epub+zip" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/epub/"><link rel="alternate" type="application/pdf" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/pdf/TSWJ2014-267872.pdf">

        <!-- Page meta end -->
    <link rel="shortcut icon" href="https://www.ncbi.nlm.nih.gov/favicon.ico"><meta name="ncbi_phid" content="F4FB45D7BC6073510000000000C400BE.m_8">
<meta name="referrer" content="origin-when-cross-origin"><link type="text/css" rel="stylesheet" href="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/4143404.css"><link type="text/css" rel="stylesheet" href="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/4157116.css" media="print"><script async="1" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/analytics.js"></script><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
</style></head>
    <body class="article" id="ui-ncbiexternallink-3"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px none; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
        <div class="grid">
            <div class="col twelve_col nomargin shadow">
                <!-- System messages like service outage or JS required; this is handled by the TemplateResources portlet -->
                <div class="sysmessages">
                    <noscript>
	<p class="nojs">
	<strong>Warning:</strong>
	The NCBI web site requires JavaScript to function. 
	<a href="/guide/browsers/#enablejs" title="Learn how to enable JavaScript" target="_blank">more...</a>
	</p>
	</noscript>
                </div>
                <!--/.sysmessage-->
                <div class="wrap">
                    <div class="page">
                        <div class="top">
                            <div class="universal_header" id="universal_header"><ul class="inline_list jig-ncbimenu ui-ncbimenu resources_list ui-ncbibasicmenu orientation_hort" id="navcontent" role="menubar"><li class="ui-ncbimenu-item-leaf ui-ncbimenu-item-first ui-helper-reset ui-ncbimenu-item-no-hlt" role="presentation"><a class="ui-ncbimenu-link-first" href="https://www.ncbi.nlm.nih.gov/" role="menuitem" title="NCBI Home" id="ncbihome" accesskey="1"><span class="offscreen_noflow">NCBI</span><img src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/28977.gif" class="ncbi_logo" title="NCBI" alt="NCBI Logo"></a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="#maincontent" title="Skip to the content" tabindex="0" accesskey="3">Skip to main
                        content</a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="#navcontent" title="Skip to the navigation" tabindex="0" accesskey="4">Skip to
                        navigation</a></li><li id="resource-menu" class="topmenu ui-helper-reset ui-ncbimenu-item-first ui-helper-reset" role="presentation"><a class="ui-ncbimenu-first-link-has-submenu ui-ncbimenu-link-first topanchor expandDown" href="https://www.ncbi.nlm.nih.gov/static/header_footer_ajax/submenu/#resources" tabindex="-1" role="menuitem">Resources</a></li><li id="all-howtos-menu" class="topmenu ui-helper-reset ui-ncbimenu-item-first" role="presentation"><a class="ui-ncbimenu-first-link-has-submenu ui-ncbimenu-link-first topanchor expandDown" href="https://www.ncbi.nlm.nih.gov/static/header_footer_ajax/submenu/#howto" tabindex="-1" role="menuitem">How To</a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="https://www.ncbi.nlm.nih.gov/guide/browsers/#accesskeys" title="About My NCBI Accesskeys" tabindex="0" accesskey="0">About NCBI Accesskeys</a></li></ul><div class="myncbi" style="top: -0.4em;"><iframe src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/emyncbi.html" style="border:none; height:2.5em; width:40em;" scrolling="no"></iframe></div></div>
                            <div class="header">
    <div class="res_logo">
  <h1 class="img_logo"><a href="https://www.ncbi.nlm.nih.gov/pmc/" class="pmc_logo offscreen">PMC</a></h1>
  <div class="NLMLogo">
    <a href="https://www.nlm.nih.gov/" title="US National Library of Medicine">US National Library of Medicine</a>
    <br>
    <a href="https://www.nih.gov/" title="National Institutes of Health">National Institutes of Health</a>
  </div>
</div>
    <div class="search"><form method="get" action="/pmc/"><div class="search_form"><label for="database" class="offscreen_noflow">Search database</label><select id="database"><optgroup label="Recent"><option value="pmc" selected="selected" data-ac_dict="pmc-search-autocomplete">PMC</option><option value="pubmed" class="last">PubMed</option></optgroup><optgroup label="All"><option value="gquery">All Databases</option><option value="assembly">Assembly</option><option value="biocollections">Biocollections</option><option value="bioproject">BioProject</option><option value="biosample">BioSample</option><option value="biosystems">BioSystems</option><option value="books">Books</option><option value="clinvar">ClinVar</option><option value="clone">Clone</option><option value="cdd">Conserved Domains</option><option value="gap">dbGaP</option><option value="dbvar">dbVar</option><option value="nucest">EST</option><option value="gene">Gene</option><option value="genome">Genome</option><option value="gds">GEO DataSets</option><option value="geoprofiles">GEO Profiles</option><option value="nucgss">GSS</option><option value="gtr">GTR</option><option value="homologene">HomoloGene</option><option value="ipg">Identical Protein Groups</option><option value="medgen">MedGen</option><option value="mesh">MeSH</option><option value="ncbisearch">NCBI Web Site</option><option value="nlmcatalog">NLM Catalog</option><option value="nuccore">Nucleotide</option><option value="omim">OMIM</option><option value="pmc" data-ac_dict="pmc-search-autocomplete">PMC</option><option value="popset">PopSet</option><option value="probe">Probe</option><option value="protein">Protein</option><option value="proteinclusters">Protein Clusters</option><option value="pcassay">PubChem BioAssay</option><option value="pccompound">PubChem Compound</option><option value="pcsubstance">PubChem Substance</option><option value="pubmed">PubMed</option><option value="pubmedhealth">PubMed Health</option><option value="snp">SNP</option><option value="sparcle">Sparcle</option><option value="sra">SRA</option><option value="structure">Structure</option><option value="taxonomy">Taxonomy</option><option value="toolkit">ToolKit</option><option value="toolkitall">ToolKitAll</option><option value="toolkitbookgh">ToolKitBookgh</option><option value="unigene">UniGene</option></optgroup></select><div class="nowrap"><label for="term" class="offscreen_noflow" accesskey="/">Search term</label><div class="nowrap"><div class="jig-ncbiclearbutton-wrap ui-ncbiclearbutton-wrap"><input name="term" id="term" title="Search PMC. Use up and down arrows to choose an item from the autocomplete." class="jig-ncbiclearbutton jig-ncbiautocomplete" data-jigconfig="dictionary:'pmc-search-autocomplete',disableUrl:'NcbiSearchBarAutoComplCtrl'" autocomplete="off" data-sbconfig="ds:'no',pjs:'no',afs:'yes'" aria-haspopup="true" aria-autocomplete="list" role="textbox" type="text"><a class="reset" href="#" style="visibility: hidden;"><img src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/clear.png" alt="Clear input"></a></div></div><button id="search" type="submit" class="button_search nowrap" cmd="go">Search</button></div></div></form><ul class="searchlinks inline_list"><li>
                        <a href="https://www.ncbi.nlm.nih.gov/pmc/advanced/">Advanced</a>
                    </li><li>
                        <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/">Journal list</a>
                    </li><li class="help">
                        <a target="_blank" href="https://www.ncbi.nlm.nih.gov/books/NBK3825/">Help</a>
                    </li></ul></div>
</div>

                            
                            
                        <!--<component id="Page" label="headcontent"/>-->
                            
                        </div>
                        <div class="content">
                            <!-- site messages -->
                            <div class="container">
    <div id="maincontent" class="content eight_col col">
        <div class="navlink-box">
            <ul class="page-breadcrumbs inline_list small"><li class="journal-list"><a href="https://www.ncbi.nlm.nih.gov/pmc/journals/" class="navlink">Journal List</a></li><li class="archive"><a class="navlink" href="https://www.ncbi.nlm.nih.gov/pmc/journals/1623/">ScientificWorldJournal</a></li><li class="issue-page"><a class="navlink" href="https://www.ncbi.nlm.nih.gov/pmc/issues/233213/">v.2014; 2014</a></li><li class="accid">PMC4099175</li></ul>
        </div>

        <!-- Journal banner -->
        <div class="pmc-page-banner whole_rhythm"><div><img src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/logo-tswj.gif" alt="Logo of tswj" usemap="#logo-imagemap"><map id="logo-imagemap" name="logo-imagemap"><area shape="rect" coords="0,0,500,75" alt="The Scientific World Journal" title="The Scientific World Journal" href="http://www.tswj.com/" ref="reftype=publisher&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A&amp;rendering-type=normal" target="pmc_ext"></map></div> </div>
        
        <!--component id='MainPortlet' label='search-reference'/-->
        
        <!-- Book content -->
        <div class="">
            
        
            
            <div class="hide-overflow article lit-style content pmc-wm slang-all page-box"><!--main-content--><div class="jig-ncbiinpagenav" data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden'" id="ui-ncbiinpagenav-1"><div class="fm-sec half_rhythm no_top_margin"><div class="fm-citation half_rhythm no_top_margin clearfix"><div class="small"><div class="inline_block eight_col va_top"><div><div><span class="cit"><span role="menubar"><a href="#" role="menuitem" aria-expanded="false" aria-haspopup="true">ScientificWorldJournal</a></span>. 2014; 2014: 267872. </span></div><div><span class="fm-vol-iss-date">Published online 2014 Jun 25. </span>  <span class="doi">doi:&nbsp; <a href="https://dx.doi.org/10.1155%2F2014%2F267872" target="pmc_ext" ref="reftype=other&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CCrosslink%7CDOI&amp;rendering-type=normal">10.1155/2014/267872</a></span></div></div></div><div class="inline_block four_col va_top show-overflow align_right"><div class="fm-citation-ids"><div class="fm-citation-pmcid"><span class="fm-citation-ids-label">PMCID: </span><span>PMC4099175</span></div><div class="fm-citation-pmid">PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25054171">25054171</a></div></div></div></div></div><h1 class="content-title">Real-Time Hand Gesture Recognition Using Finger Segmentation</h1><div class="half_rhythm"><div class="contrib-group fm-author"><a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Chen%20Zh%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171" class="affpopup" co-rid="_co_idm139829726022032" co-class="co-affbox">Zhi-hua Chen</a>,<sup>
1
</sup> <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Kim%20JT%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171" class="affpopup" co-rid="_co_idm139829655298256" co-class="co-affbox">Jung-Tae Kim</a>,<sup>
1
</sup> <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Liang%20J%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171" class="affpopup" co-rid="_co_idm139829656876576" co-class="co-affbox">Jianning Liang</a>,<sup>
1
,</sup><sup>*</sup> <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Zhang%20J%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171" class="affpopup" co-rid="_co_idm139829694785616" co-class="co-affbox">Jing Zhang</a>,<sup>
1
,</sup><sup>
2
</sup> and  <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Yuan%20YB%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171" class="affpopup" co-rid="_co_idm139829641114304" co-class="co-affbox">Yu-Bo Yuan</a><sup>
1
,</sup><sup>*</sup></div><div style="display:none" class="contrib-group aff-tip"><div id="_co_idm139829726022032"><h3 class="no_margin">Zhi-hua Chen</h3><p>  <sup>1</sup>Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai 200237, China</p><div>Find articles by <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Chen%20Zh%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171">Zhi-hua Chen</a></div></div><div id="_co_idm139829655298256"><h3 class="no_margin">Jung-Tae Kim</h3><p>  <sup>1</sup>Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai 200237, China</p><div>Find articles by <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Kim%20JT%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171">Jung-Tae Kim</a></div></div><div id="_co_idm139829656876576"><h3 class="no_margin">Jianning Liang</h3><p>  <sup>1</sup>Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai 200237, China</p><div>Find articles by <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Liang%20J%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171">Jianning Liang</a></div></div><div id="_co_idm139829694785616"><h3 class="no_margin">Jing Zhang</h3><p>  <sup>1</sup>Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai 200237, China</p><p>  <sup>2</sup>State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, China</p><div>Find articles by <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Zhang%20J%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171">Jing Zhang</a></div></div><div id="_co_idm139829641114304"><h3 class="no_margin">Yu-Bo Yuan</h3><p>  <sup>1</sup>Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai 200237, China</p><div>Find articles by <a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=Yuan%20YB%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=25054171">Yu-Bo Yuan</a></div></div></div></div><div class="fm-panel small half_rhythm"><div class="fm-authors-info fm-panel hide half_rhythm" id="idm139829650932032_ai" style="display:none"><div class="fm-affl" id="I1" lang="en">  <sup>1</sup>Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai 200237, China</div><div class="fm-affl" id="I2" lang="en">  <sup>2</sup>State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, China</div><div id="cor1">*Jianning Liang: <a href="mailto:dev@null" data-email="nc.ude.tsuce@gnail.n.j" class="oemail">nc.ude.tsuce@gnail.n.j</a> and </div><div id="cor2">*Yu-Bo Yuan: <a href="mailto:dev@null" data-email="nc.ude.tsuce@nauyby" class="oemail">nc.ude.tsuce@nauyby</a></div><div id="idm139829653520192">Academic Editor: Shan Zhao</div></div><div class="togglers"><a href="#" class="pmctoggle" rid="idm139829650932032_ai">Author information <span>►</span></a> <a href="#" class="pmctoggle" rid="idm139829650932032_an">Article notes <span>►</span></a> <a href="#" class="pmctoggle" rid="idm139829650932032_cpl">Copyright and License information <span>►</span></a> <a href="https://www.ncbi.nlm.nih.gov/pmc/about/disclaimer/">Disclaimer</a></div><div class="fm-article-notes fm-panel hide half_rhythm" id="idm139829650932032_an" style="display:none"><div class="fm-pubdate half_rhythm">Received 2014 Apr 24; Accepted 2014 May 29.</div></div><div class="fm-cpl-info fm-panel hide half_rhythm" id="idm139829650932032_cpl" style="display:none"><div class="fm-copyright half_rhythm"><a href="https://www.ncbi.nlm.nih.gov/pmc/about/copyright/">Copyright</a>  © 2014 Zhi-hua Chen et al.</div><div class="fm-copyright half_rhythm"><div class="license">This
 is an open access article distributed under the Creative Commons 
Attribution License, which permits unrestricted use, distribution, and 
reproduction in any medium, provided the original work is properly 
cited.</div></div></div></div><div id="pmclinksbox" class="links-box whole_rhythm hidden"></div></div><div class="sec"></div><div id="idm139829647637120" class="tsec sec" lang="en"><div class="goto jig-ncbiinpagenav-goto-container"><span role="menubar"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="menuitem" aria-expanded="false" aria-haspopup="true">Go to:</a></span></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="idm139829647637120title">Abstract</h2><!--article-meta--><div><p id="__p2" class="p p-first-last">Hand
 gesture recognition is very significant for human-computer interaction.
 In this work, we present a novel real-time method for hand gesture 
recognition. In our framework, the hand region is extracted from the 
background with the background subtraction method. Then, the palm and 
fingers are segmented so as to detect and recognize the fingers. 
Finally, a rule classifier is applied to predict the labels of hand 
gestures. The experiments on the data set of 1300 images show that our 
method performs well and is highly efficient. Moreover, our method shows
 better performance than a state-of-art method on another data set of 
hand gestures.</p></div></div><div id="sec1" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec1title">1. Introduction</h2><p id="__p3" class="p p-first">As
 we know, the vision-based technology of hand gesture recognition is an 
important part of human-computer interaction (HCI). In the last decades,
 keyboard and mouse play a significant role in human-computer 
interaction. However, owing to the rapid development of hardware and 
software, new types of HCI methods have been required. In particular, 
technologies such as speech recognition and gesture recognition receive 
great attention in the field of HCI.</p><p id="__p4">Gesture is a symbol
 of physical behavior or emotional expression. It includes body gesture 
and hand gesture. It falls into two categories: static gesture [<a href="#B1" rid="B1" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">1</a>–<a href="#B4" rid="B4" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">4</a>] and dynamic gesture [<a href="#B5" rid="B5" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">5</a>–<a href="#B8" rid="B8" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">8</a>].
 For the former, the posture of the body or the gesture of the hand 
denotes a sign. For the latter, the movement of the body or the hand 
conveys some messages. Gesture can be used as a tool of communication 
between computer and human [<a href="#B9" rid="B9" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>–<a href="#B11" rid="B11" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">11</a>].
 It is greatly different from the traditional hardware based methods and
 can accomplish human-computer interaction through gesture recognition. 
Gesture recognition determines the user intent through the recognition 
of the gesture or movement of the body or body parts. In the past 
decades, many researchers have strived to improve the hand gesture 
recognition technology. Hand gesture recognition has great value in many
 applications such as sign language recognition [<a href="#B12" rid="B12" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_625562989" role="button" aria-expanded="false" aria-haspopup="true">12</a>–<a href="#B15" rid="B15" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>], augmented reality (virtual reality) [<a href="#B16" rid="B16" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">16</a>–<a href="#B19" rid="B19" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">19</a>], sign language interpreters for the disabled [<a href="#B20" rid="B20" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">20</a>], and robot control [<a href="#B21" rid="B21" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">21</a>, <a href="#B22" rid="B22" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">22</a>].</p><p id="__p5">In [<a href="#B12" rid="B12" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_625562988" role="button" aria-expanded="false" aria-haspopup="true">12</a>, <a href="#B13" rid="B13" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>],
 the authors detect the hand region from input images and then track and
 analyze the moving path to recognize America sign language. In [<a href="#B23" rid="B23" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">23</a>], Shimada et al. propose a TV control interface using hand gesture recognition. Keskin et al. [<a href="#B24" rid="B24" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>]
 divide the hand into 21 different regions and train a SVM classifier to
 model the joint distribution of these regions for various hand gestures
 so as to classify the gestures. Zeng et al. [<a href="#B20" rid="B20" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">20</a>]
 improve the medical service through the hand gesture recognition. The 
HCI recognition system of the intelligent wheelchair includes five hand 
gestures and three compound states. Their system performs reliably in 
the environment of indoor and outdoor and in the condition of lighting 
change.</p><p id="__p6">The work flow of hand gesture recognition [<a href="#B25" rid="B25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>–<a href="#B27" rid="B27" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">27</a>]
 is described as follows. First, the hand region is detected from the 
original images from the input devices. Then, some kinds of features are
 extracted to describe hand gestures. Last, the recognition of hand 
gestures is accomplished by measuring the similarity of the feature 
data. The input devices providing the original image information 
includes normal camera, stereo camera, and ToF (time of flight) camera. 
The stereo camera and ToF camera additionally provide the depth 
information so it is easy to segment the hand region from the background
 in terms of the depth map. For the normal camera, the skin color 
sensitive to the lighting condition and feature points are combined to 
robustly detect and segment the hand region. When the region of interest
 (ROI, the hand region in the case) is detected, features are needed to 
be extracted from the ROI region. Color, brightness, and gradient values
 are widely used features. Li and Kitani [<a href="#B28" rid="B28" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">28</a>]
 describe various features for hand region detecting including the Gabor
 filter response, HOG, SIFT, BRIEF, and ORB. For the recognition of hand
 gestures, various classifiers, for example, SVM (support vector 
machine), HMM (hidden Markov model), CRF (conditional random field), and
 adapted boosting classifier are trained to discriminate hand gestures. 
Although the recognition performance of these sophisticated classifiers 
is good, the time cost is very high.</p><p id="__p7">In this paper, we 
present an efficient and effective method for hand gesture recognition. 
The hand region is detected through the background subtraction method. 
Then, the palm and fingers are split so as to recognize the fingers. 
After the fingers are recognized, the hand gesture can be classified 
through a simple rule classifier.</p><p id="__p8">The novelty of the proposed method is listed as follows.</p><ol class="enumerated" style="list-style-type:lower-roman"><!--
list-behavior=enumerated
prefix-word=
mark-type=lower-roman
max-label-size=0
--><li><div>The first novelty of the proposed method is that the hand 
gesture recognition is based on the result of finger recognition. 
Therefore, the recognition is accomplished by a simple and efficient 
rule classifier instead of the sophisticated but complicated classifiers
 such as SVM and CRF.</div></li><li><div>Some previous works need the users to wear data glove [<a href="#B29" rid="B29" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">29</a>]
 to acquire hand gesture data. However, the special sensors of data 
glove are expensive and hinder its wide application in real life. In the
 work [<a href="#B25" rid="B25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>],
 the authors use TOF camera, that is, Kinect sensor, to capture the 
depth of the environment and a special tape worn across the wrist to 
detect hand region. Our approach only uses a normal camera to capture 
the vision information of the hand gesture meanwhile does not need the 
help of the special tape to detect hand regions.</div></li><li><div>The third advantage of the proposed method is that it is highly efficient and fit for real-time applications.</div></li></ol><p>
</p><p id="__p12" class="p p-last">The rest of the paper is organized as follows. In <a href="#sec2" rid="sec2" class=" sec">Section 2</a>, the proposed method for hand gesture recognition is described in detail. In <a href="#sec3" rid="sec3" class=" sec">Section 3</a>,
 the performance of our approach is evaluated on a data set of hand 
gestures. Then, our method is compared with a state-of-art method (FEMD)
 [<a href="#B25" rid="B25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>] on another data set of hand gestures. <a href="#sec4" rid="sec4" class=" sec"> Section 4</a> presents the conclusion and future works.</p></div><div id="sec2" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec2title">2. The Proposed Method for Hand Gesture Recognition</h2><div id="sec2.1" class="sec sec-first"><h3>2.1. The Overview of the Method</h3><p id="__p13" class="p p-first-last">The overview of the hand gesture recognition is described in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig1/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig1" rid-ob="ob-fig1" co-legend-rid="lgnd_fig1"><span>Figure 1</span></a>.
 First, the hand is detected using the background subtraction method and
 the result of hand detection is transformed to a binary image. Then, 
the fingers and palm are segmented so as to facilitate the finger 
recognition. Moreover, the fingers are detected and recognized. Last, 
hand gestures are recognized using a simple rule classifier.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig1" co-legend-rid="lgnd_fig1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig1/" target="figure" rid-figpopup="fig1" rid-ob="ob-fig1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829649915248" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.001.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.001.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_011.jpg"></div></a><div id="largeobj_idm139829649915248" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig1/" target="figure" rid-figpopup="fig1" rid-ob="ob-fig1"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig1/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig1"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig1/" target="figure" rid-figpopup="fig1" rid-ob="ob-fig1">Figure 1</a></div><!--caption a7--><div class="caption"><p id="__p40">The overview of the proposed method for hand gesture recognition.</p></div></div></div></div><div id="sec2.2" class="sec"><h3>2.2. Hand Detection</h3><p id="__p14" class="p p-first-last">The original images used for hand gesture recognition in the work are demonstrated in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig2/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig2" rid-ob="ob-fig2" co-legend-rid="lgnd_fig2"><span>Figure 2</span></a>.
 These images are captured with a normal camera. These hand images are 
taken under the same condition. The background of these images is 
identical. So, it is easy and effective to detect the hand region from 
the original image using the background subtraction method. However, in 
some cases, there are other moving objects included in the result of 
background subtraction. The skin color can be used to discriminate the 
hand region from the other moving objects. The color of the skin is 
measured with the HSV model. The HSV (hue, saturation, and value) value 
of the skin color is 315, 94, and 37, respectively. The image of the 
detected hand is resized to 200 × 200 to make the gesture recognition 
invariant to image scale.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig2" co-legend-rid="lgnd_fig2"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig2/" target="figure" rid-figpopup="fig2" rid-ob="ob-fig2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829691106000" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.002.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.002.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_015.jpg"></div></a><div id="largeobj_idm139829691106000" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig2/" target="figure" rid-figpopup="fig2" rid-ob="ob-fig2"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig2/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig2"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig2/" target="figure" rid-figpopup="fig2" rid-ob="ob-fig2">Figure 2</a></div><!--caption a7--><div class="caption"><p id="__p41">The procedure of hand detection.</p></div></div></div></div><div id="sec2.3" class="sec"><h3>2.3. Fingers and Palm Segmentation</h3><p id="__p15" class="p p-first">The
 output of the hand detection is a binary image in which the white 
pixels are the members of the hand region, while the black pixels belong
 to the background. An example of the hand detection result is shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig3" rid-ob="ob-fig3" co-legend-rid="lgnd_fig3"><span>Figure 3</span></a>. Then, the following procedure is implemented on the binary hand image to segment the fingers and palm.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig3" co-legend-rid="lgnd_fig3"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" rid-figpopup="fig3" rid-ob="ob-fig3"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829653092480" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.003.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.003.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_009.jpg"></div></a><div id="largeobj_idm139829653092480" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" rid-figpopup="fig3" rid-ob="ob-fig3"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig3"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" rid-figpopup="fig3" rid-ob="ob-fig3">Figure 3</a></div><!--caption a7--><div class="caption"><p id="__p42">The detected hand region.</p></div></div></div><p id="__p16">
<em>(i) Palm Point.</em> The palm point is defined as the center point 
of the palm. It is found by the method of distance transform. Distance 
transform also called distance map is a representation of an image. In 
the distance transform image, each pixel records the distance of it and 
the nearest boundary pixel. An example of distance transform is 
demonstrated in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig4" rid-ob="ob-fig4" co-legend-rid="lgnd_fig4"><span>Figure 4</span></a>. In <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig4" rid-ob="ob-fig4" co-legend-rid="lgnd_fig4"><span>Figure 4(a)</span></a> is a binary image and in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig4" rid-ob="ob-fig4" co-legend-rid="lgnd_fig4"><span>Figure 4(b)</span></a>
 is the distance transform image. The block city distance is used to 
measure the distances between the pixels and the nearest boundary 
pixels. As is shown in the figure, the center point of the binary image 
is with the largest distance 4. Thus, in the distance transform image 
(refer to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig5/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig5" rid-ob="ob-fig5" co-legend-rid="lgnd_fig5"><span>Figure 5</span></a>)
 of the binary hand image, the pixel with largest distance is chosen as 
the palm point. The found palm point is marked with the point of the 
green color in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig6" rid-ob="ob-fig6" co-legend-rid="lgnd_fig6"><span>Figure 6</span></a>.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig4" co-legend-rid="lgnd_fig4"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/" target="figure" rid-figpopup="fig4" rid-ob="ob-fig4"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829694240512" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.004.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.004.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_012.jpg"></div></a><div id="largeobj_idm139829694240512" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/" target="figure" rid-figpopup="fig4" rid-ob="ob-fig4"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig4"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig4/" target="figure" rid-figpopup="fig4" rid-ob="ob-fig4">Figure 4</a></div><!--caption a7--><div class="caption"><p id="__p43">An example of distance transform: (a) is a binary image; (b) is the distance transform.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig5" co-legend-rid="lgnd_fig5"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig5/" target="figure" rid-figpopup="fig5" rid-ob="ob-fig5"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829648849360" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.005.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.005.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_019.jpg"></div></a><div id="largeobj_idm139829648849360" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig5/" target="figure" rid-figpopup="fig5" rid-ob="ob-fig5"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig5/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig5"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig5/" target="figure" rid-figpopup="fig5" rid-ob="ob-fig5">Figure 5</a></div><!--caption a7--><div class="caption"><p id="__p44">The distance transform of the hand image in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig3" rid-ob="ob-fig3" co-legend-rid="lgnd_fig3"><span>Figure 3</span></a>.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig6" co-legend-rid="lgnd_fig6"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" rid-figpopup="fig6" rid-ob="ob-fig6"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829645705440" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.006.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.006.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_017.jpg"></div></a><div id="largeobj_idm139829645705440" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" rid-figpopup="fig6" rid-ob="ob-fig6"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig6"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" rid-figpopup="fig6" rid-ob="ob-fig6">Figure 6</a></div><!--caption a7--><div class="caption"><p id="__p45">The palm point, wrist points, the wrist line, and the inner circle of the maximal radius.</p></div></div></div><p id="__p17">
<em>(ii) Inner Circle of the Maximal Radius.</em> When the palm point is
 found, it can draw a circle with the palm point as the center point 
inside the palm. The circle is called the inner circle because it is 
included inside the palm. The radius of the circle gradually increases 
until it reaches the edge of the palm. That is the radius of the circle 
stops to increase when the black pixels are included in the circle. The 
circle is the inner circle of the maximal radius which is drawn as the 
circle with the red color in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig6" rid-ob="ob-fig6" co-legend-rid="lgnd_fig6"><span>Figure 6</span></a>.</p><p id="__p18">
<em>(iii) Wrist Points and Palm Mask.</em> When the radius of the 
maximal inner circle is acquired, a larger circle the radius of which is
 1.2 times of that of the maximal inner circle is produced. The circle 
is drawn as the blue color circle in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig6" rid-ob="ob-fig6" co-legend-rid="lgnd_fig6"><span>Figure 6</span></a>. Then, some points (<em>X</em>, <em>Y</em>) are sampled uniformly along the circle. That is,
</p><div class="disp-formula" id="EEq1"><div class="f"><span class="MathJax_Preview"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style=""><nobr><span class="math" id="M1" overflow="scroll" role="math" style="width: 28.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 20.773em; height: 0px; font-size: 139%;"><span style="position: absolute; clip: rect(0.352em, 1020.55em, 3.375em, -1000em); top: -2.113em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mtable" id="MathJax-Span-3" style="padding-right: 0.167em; padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 20.442em; height: 0px;"><span style="position: absolute; clip: rect(2.24em, 1020.39em, 5.204em, -1000em); top: -4.002em; left: 0em;"><span style="display: inline-block; position: relative; width: 20.442em; height: 0px;"><span style="position: absolute; clip: rect(2.98em, 1020.39em, 4.519em, -1000em); top: -4.742em; left: 50%; margin-left: -10.221em;"><span class="mtd" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="malignmark" id="MathJax-Span-6"></span><span class="mi" id="MathJax-Span-7" style="font-family: STIXGeneral; font-style: italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.044em;"></span></span><span class="mo" id="MathJax-Span-8" style="font-family: STIXGeneral; padding-left: 0.313em;">=</span><span class="mi" id="MathJax-Span-9" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.313em;">R</span><span class="mi" id="MathJax-Span-10" style="font-family: STIXGeneral; padding-left: 0.188em;">cos</span><span class="mo" id="MathJax-Span-11"></span><span class="mrow" id="MathJax-Span-12"><span class="mo" id="MathJax-Span-13" style="vertical-align: -0.201em;"><span style="font-family: STIXSizeOneSym;">(</span></span><span class="mrow" id="MathJax-Span-14"><span class="mfrac" id="MathJax-Span-15"><span style="display: inline-block; position: relative; width: 1.218em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.387em, 1001.1em, 4.149em, -1000em); top: -4.409em; left: 50%; margin-left: -0.549em;"><span class="mrow" id="MathJax-Span-16"><span class="mi" id="MathJax-Span-17" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.01em;"></span></span><span class="mi" id="MathJax-Span-18" style="font-size: 70.7%; font-family: STIXGeneral;">∗</span><span class="mi" id="MathJax-Span-19" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">π<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.023em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.389em, 1001.04em, 4.147em, -1000em); top: -3.629em; left: 50%; margin-left: -0.53em;"><span class="mrow" id="MathJax-Span-20"><span class="mn" id="MathJax-Span-21" style="font-size: 70.7%; font-family: STIXGeneral;">180</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.884em, 1001.22em, 1.214em, -1000em); top: -1.299em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.218em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-22" style="vertical-align: -0.201em;"><span style="font-family: STIXSizeOneSym;">)</span></span></span><span class="mo" id="MathJax-Span-23" style="font-family: STIXGeneral; padding-left: 0.25em;">+</span><span class="msub" id="MathJax-Span-24" style="padding-left: 0.25em;"><span style="display: inline-block; position: relative; width: 1.04em; height: 0px;"><span style="position: absolute; clip: rect(3.214em, 1000.66em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-25"><span class="mi" id="MathJax-Span-26" style="font-family: STIXGeneral; font-style: italic;">X<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.044em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.611em;"><span class="mrow" id="MathJax-Span-27"><span class="mn" id="MathJax-Span-28" style="font-size: 70.7%; font-family: STIXGeneral;">0</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-29" style="font-family: STIXGeneral;">,</span><span class="mo" id="MathJax-Span-30" style="font-family: STIXGeneral; padding-left: 0.188em;"><span style="margin-left: 1em;"></span></span><span class="mo" id="MathJax-Span-31" style="font-family: STIXGeneral; padding-left: 0.188em;"><span style="margin-left: 1em;"></span></span><span class="mi" id="MathJax-Span-32" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.188em;">Y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span><span class="mo" id="MathJax-Span-33" style="font-family: STIXGeneral; padding-left: 0.313em;">=</span><span class="mi" id="MathJax-Span-34" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.313em;">R</span><span class="mi" id="MathJax-Span-35" style="font-family: STIXGeneral; padding-left: 0.188em;">sin</span><span class="mrow" id="MathJax-Span-36" style="padding-left: 0.188em;"><span class="mo" id="MathJax-Span-37" style="vertical-align: -0.201em;"><span style="font-family: STIXSizeOneSym;">(</span></span><span class="mrow" id="MathJax-Span-38"><span class="mfrac" id="MathJax-Span-39"><span style="display: inline-block; position: relative; width: 1.218em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(3.387em, 1001.1em, 4.149em, -1000em); top: -4.409em; left: 50%; margin-left: -0.549em;"><span class="mrow" id="MathJax-Span-40"><span class="mi" id="MathJax-Span-41" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.01em;"></span></span><span class="mi" id="MathJax-Span-42" style="font-size: 70.7%; font-family: STIXGeneral;">∗</span><span class="mi" id="MathJax-Span-43" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">π<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.023em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.389em, 1001.04em, 4.147em, -1000em); top: -3.629em; left: 50%; margin-left: -0.53em;"><span class="mrow" id="MathJax-Span-44"><span class="mn" id="MathJax-Span-45" style="font-size: 70.7%; font-family: STIXGeneral;">180</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.884em, 1001.22em, 1.214em, -1000em); top: -1.299em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.218em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-46" style="vertical-align: -0.201em;"><span style="font-family: STIXSizeOneSym;">)</span></span></span><span class="mo" id="MathJax-Span-47" style="font-family: STIXGeneral; padding-left: 0.25em;">+</span><span class="msub" id="MathJax-Span-48" style="padding-left: 0.25em;"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.214em, 1000.63em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-49"><span class="mi" id="MathJax-Span-50" style="font-family: STIXGeneral; font-style: italic;">Y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.556em;"><span class="mrow" id="MathJax-Span-51"><span class="mn" id="MathJax-Span-52" style="font-size: 70.7%; font-family: STIXGeneral;">0</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-53" style="font-family: STIXGeneral;">,</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.183em, 1006.1em, 4.278em, -1000em); top: -3.075em; left: 50%; margin-left: -3.079em;"><span class="mtd" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="maligngroup" id="MathJax-Span-56"></span><span class="malignmark" id="MathJax-Span-57"></span><span class="mi" id="MathJax-Span-58" style="font-family: STIXGeneral; font-style: italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.014em;"></span></span><span class="mo" id="MathJax-Span-59" style="font-family: STIXGeneral; padding-left: 0.313em;">=</span><span class="mn" id="MathJax-Span-60" style="font-family: STIXGeneral; padding-left: 0.313em;">0</span><span class="mo" id="MathJax-Span-61" style="font-family: STIXGeneral; padding-left: 0.313em;">:</span><span class="mi" id="MathJax-Span-62" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.313em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.018em;"></span></span><span class="mo" id="MathJax-Span-63" style="font-family: STIXGeneral; padding-left: 0.313em;">:</span><span class="mn" id="MathJax-Span-64" style="font-family: STIXGeneral; padding-left: 0.313em;">360</span><span class="mo" id="MathJax-Span-65" style="font-family: STIXGeneral;">,</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.113em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.628em; border-left: 0px solid; width: 0px; height: 3.952em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-1"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M1" overflow="scroll"><mtable><mtr><mtd><malignmark></malignmark><mi>X</mi><mo>=</mo><mi>R</mi><mi>cos</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><mfrac><mrow><mi>θ</mi><mi>∗</mi><mi>π</mi></mrow><mrow><mn mathvariant="normal">180</mn></mrow></mfrac></mrow><mo>)</mo></mrow><mo>+</mo><msub><mrow><mi>X</mi></mrow><mrow><mn mathvariant="normal">0</mn></mrow></msub><mo>,</mo><mo> </mo><mo> </mo><mi>Y</mi><mo>=</mo><mi>R</mi><mi>sin</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mi>θ</mi><mi>∗</mi><mi>π</mi></mrow><mrow><mn mathvariant="normal">180</mn></mrow></mfrac></mrow><mo>)</mo></mrow><mo>+</mo><msub><mrow><mi>Y</mi></mrow><mrow><mn mathvariant="normal">0</mn></mrow></msub><mo>,</mo></mtd></mtr><mtr><mtd><maligngroup></maligngroup><malignmark></malignmark><mi>θ</mi><mo>=</mo><mn mathvariant="normal">0</mn><mo>:</mo><mi>t</mi><mo>:</mo><mn mathvariant="normal">360</mn><mo>,</mo></mtd></mtr></mtable></math></script></div><div class="l">(1)</div></div><p>
</p><p id="__p19">
where (<em>X</em>
<sub>0</sub>, <em>Y</em>
<sub>0</sub>) is the position of the palm point, <em>R</em> is the radius of the circle, and <em>t</em> is the sampling step.</p><p id="__p20">For
 each sampled point on the circle, its nearest boundary point is found 
and lined to it. The boundary point is judged in a simple way. If the 8 
neighbors of a pixel consist of white and black pixels, it is labeled as
 a boundary point. All of the nearest boundary points found are linked 
to yield the palm mask that can be used to segment fingers and the palm.
 The method for searching the palm mask is described in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/alg1/" target="figure" class="fig-table-link figpopup" rid-figpopup="alg1" rid-ob="ob-alg1" co-legend-rid="lgnd_alg1"><span>Algorithm 1</span></a>. The palm mask of the hand image of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig3" rid-ob="ob-fig3" co-legend-rid="lgnd_fig3"><span>Figure 3</span></a> is demonstrated in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig7/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig7" rid-ob="ob-fig7" co-legend-rid="lgnd_fig7"><span>Figure 7</span></a>.
 A larger circle instead of the maximal inner circle is used so as to 
yield a more accurate palm mask for the following segmentation.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig7" co-legend-rid="lgnd_fig7"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig7/" target="figure" rid-figpopup="fig7" rid-ob="ob-fig7"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829645612384" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.007.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.007.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_003.jpg"></div></a><div id="largeobj_idm139829645612384" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig7/" target="figure" rid-figpopup="fig7" rid-ob="ob-fig7"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig7/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig7"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig7/" target="figure" rid-figpopup="fig7" rid-ob="ob-fig7">Figure 7</a></div><!--caption a7--><div class="caption"><p id="__p46">The palm mask.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="alg1" co-legend-rid="lgnd_alg1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/alg1/" target="figure" rid-figpopup="alg1" rid-ob="ob-alg1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829657983104" class="figure"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/alg1/" target="figure" rid-figpopup="alg1" rid-ob="ob-alg1"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4099175_TSWJ2014-267872.alg.001.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.alg.001.jpg" title="Click on image to zoom" class="tileshop" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872.jpg"></a></div><div id="largeobj_idm139829657983104" class="largeobj-link align_right" style="display: none"><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/alg1/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_alg1"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/alg1/" target="figure" rid-figpopup="alg1" rid-ob="ob-alg1">Algorithm 1</a></div><!--caption a7--><div class="caption"><p id="__p58">The method of producing the palm mask.</p></div></div></div><p id="__p21">Two
 wrist points are the two ending points of the wrist line across the 
bottom of the hand. The wrist points are important points for hand 
gesture recognition. They can be searched in the following manner: if 
the distance between two successive mask points <em>P</em>
<sub><em>i</em></sub>, <em>P</em>
<sub><em>i</em>+1</sub> are large, these two mask points are judged as the wrist points. That is,
</p><div class="disp-formula" id="EEq2"><div class="f"><span class="MathJax_Preview"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style=""><nobr><span class="math" id="M2" overflow="scroll" role="math" style="width: 22.078em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.872em; height: 0px; font-size: 139%;"><span style="position: absolute; clip: rect(0.873em, 1015.65em, 2.854em, -1000em); top: -2.113em; left: 0em;"><span class="mrow" id="MathJax-Span-67"><span class="mtable" id="MathJax-Span-68" style="padding-right: 0.167em; padding-left: 0.167em;"><span style="display: inline-block; position: relative; width: 15.559em; height: 0px;"><span style="position: absolute; clip: rect(2.878em, 1015.5em, 4.742em, -1000em); top: -4.002em; left: 0em;"><span style="display: inline-block; position: relative; width: 15.559em; height: 0px;"><span style="position: absolute; clip: rect(3.184em, 1015.5em, 5.048em, -1000em); top: -4.308em; left: 50%; margin-left: -7.779em;"><span class="mtd" id="MathJax-Span-69"><span class="mrow" id="MathJax-Span-70"><span class="mi" id="MathJax-Span-71" style="font-family: STIXGeneral;">arg</span><span class="mrow" id="MathJax-Span-72" style="padding-left: 0.188em;"><span class="mrow" id="MathJax-Span-73"><span class="munder" id="MathJax-Span-74"><span style="display: inline-block; position: relative; width: 2.017em; height: 0px;"><span style="position: absolute; clip: rect(3.407em, 1001.72em, 4.147em, -1000em); top: -4.002em; left: 0.148em;"><span class="mrow" id="MathJax-Span-75"><span class="mi" id="MathJax-Span-76" style="font-family: STIXGeneral;">max</span><span class="mo" id="MathJax-Span-77"></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.405em, 1002.02em, 4.363em, -1000em); top: -3.317em; left: 0em;"><span class="mrow" id="MathJax-Span-78"><span class="msub" id="MathJax-Span-79"><span style="display: inline-block; position: relative; width: 0.624em; height: 0px;"><span style="position: absolute; clip: rect(3.405em, 1000.43em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-80"><span class="mi" id="MathJax-Span-81" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">P</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.896em; left: 0.432em;"><span class="mrow" id="MathJax-Span-82"><span class="mi" id="MathJax-Span-83" style="font-size: 50%; font-family: STIXGeneral; font-style: italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-84" style="font-size: 70.7%; font-family: STIXGeneral;">,</span><span class="msub" id="MathJax-Span-85"><span style="display: inline-block; position: relative; width: 1.217em; height: 0px;"><span style="position: absolute; clip: rect(3.405em, 1000.43em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-86"><span class="mi" id="MathJax-Span-87" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">P</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.896em; left: 0.432em;"><span class="mrow" id="MathJax-Span-88"><span class="mi" id="MathJax-Span-89" style="font-size: 50%; font-family: STIXGeneral; font-style: italic;">i</span><span class="mo" id="MathJax-Span-90" style="font-size: 50%; font-family: STIXGeneral;">+</span><span class="mn" id="MathJax-Span-91" style="font-size: 50%; font-family: STIXGeneral;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-92"></span><span class="mrow" id="MathJax-Span-93" style="padding-left: 0.188em;"><span class="mi" id="MathJax-Span-94" style="font-family: STIXGeneral;">dist</span><span class="mo" id="MathJax-Span-95"></span><span class="mrow" id="MathJax-Span-96"><span class="mo" id="MathJax-Span-97" style="vertical-align: 0em;"><span style="font-family: STIXGeneral;">(</span></span><span class="mrow" id="MathJax-Span-98"><span class="msub" id="MathJax-Span-99"><span style="display: inline-block; position: relative; width: 0.883em; height: 0px;"><span style="position: absolute; clip: rect(3.214em, 1000.61em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-100"><span class="mi" id="MathJax-Span-101" style="font-family: STIXGeneral; font-style: italic;">P</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.611em;"><span class="mrow" id="MathJax-Span-102"><span class="mi" id="MathJax-Span-103" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-104" style="font-family: STIXGeneral;">,</span><span class="msub" id="MathJax-Span-105" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 1.72em; height: 0px;"><span style="position: absolute; clip: rect(3.214em, 1000.61em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-106"><span class="mi" id="MathJax-Span-107" style="font-family: STIXGeneral; font-style: italic;">P</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.611em;"><span class="mrow" id="MathJax-Span-108"><span class="mi" id="MathJax-Span-109" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">i</span><span class="mo" id="MathJax-Span-110" style="font-size: 70.7%; font-family: STIXGeneral;">+</span><span class="mn" id="MathJax-Span-111" style="font-size: 70.7%; font-family: STIXGeneral;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-112" style="vertical-align: 0em;"><span style="font-family: STIXGeneral;">)</span></span></span><span class="mo" id="MathJax-Span-113" style="font-family: STIXGeneral;">,</span></span></span><span class="mo" id="MathJax-Span-114" style="font-family: STIXGeneral; padding-left: 0.188em;"><span style="margin-left: 1em;"></span></span><span class="msub" id="MathJax-Span-115" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 0.883em; height: 0px;"><span style="position: absolute; clip: rect(3.214em, 1000.61em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-116"><span class="mi" id="MathJax-Span-117" style="font-family: STIXGeneral; font-style: italic;">P</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.611em;"><span class="mrow" id="MathJax-Span-118"><span class="mi" id="MathJax-Span-119" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-120" style="font-family: STIXGeneral;">,</span><span class="msub" id="MathJax-Span-121" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 1.72em; height: 0px;"><span style="position: absolute; clip: rect(3.214em, 1000.61em, 4.137em, -1000em); top: -4.002em; left: 0em;"><span class="mrow" id="MathJax-Span-122"><span class="mi" id="MathJax-Span-123" style="font-family: STIXGeneral; font-style: italic;">P</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.611em;"><span class="mrow" id="MathJax-Span-124"><span class="mi" id="MathJax-Span-125" style="font-size: 70.7%; font-family: STIXGeneral; font-style: italic;">i</span><span class="mo" id="MathJax-Span-126" style="font-size: 70.7%; font-family: STIXGeneral;">+</span><span class="mn" id="MathJax-Span-127" style="font-size: 70.7%; font-family: STIXGeneral;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-128" style="font-family: STIXGeneral; padding-left: 0.313em;">∈</span><span class="mi" id="MathJax-Span-129" style="font-family: STIXGeneral; font-style: italic; padding-left: 0.313em;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.008em;"></span></span><span class="mo" id="MathJax-Span-130" style="font-family: STIXGeneral;">,</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.113em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.905em; border-left: 0px solid; width: 0px; height: 2.504em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-2"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M2" overflow="scroll"><mtable><mtr><mtd><mi>arg</mi><mrow><mrow><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mrow><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn mathvariant="normal">1</mn></mrow></msub></mrow></munder></mrow><mo>⁡</mo><mrow><mi>dist</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn mathvariant="normal">1</mn></mrow></msub></mrow><mo>)</mo></mrow><mo>,</mo></mrow></mrow><mo> </mo><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi><mo>+</mo><mn mathvariant="normal">1</mn></mrow></msub><mo>∈</mo><mi>S</mi><mo>,</mo></mtd></mtr></mtable></math></script></div><div class="l">(2)</div></div><p>
where <em>S</em> is the set of palm mask points and dist⁡(∗, ∗) is the distance between two points. Please refer to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig6" rid-ob="ob-fig6" co-legend-rid="lgnd_fig6"><span>Figure 6</span></a> for the wrist points and wrist line.</p><p id="__p22">
<em>(iv) Hand Rotation.</em> When the palm point and wrist point are 
obtained, it can yield an arrow pointing from the palm point to the 
middle point of the wrist line at the bottom of the hand. Then, the 
arrow is adjusted to the direction of the north. The hand image rotates 
synchronously so as to make the hand gesture invariant to the rotation. 
Meanwhile, the parts below the wrist line in the rotated image are cut 
to produce an accurate hand image that does not enclose the part of the 
arm. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig8/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig8" rid-ob="ob-fig8" co-legend-rid="lgnd_fig8"><span> Figure 8</span></a> is the rotated and cut hand image.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig8" co-legend-rid="lgnd_fig8"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig8/" target="figure" rid-figpopup="fig8" rid-ob="ob-fig8"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829650401152" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.008.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.008.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_008.jpg"></div></a><div id="largeobj_idm139829650401152" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig8/" target="figure" rid-figpopup="fig8" rid-ob="ob-fig8"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig8/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig8"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig8/" target="figure" rid-figpopup="fig8" rid-ob="ob-fig8">Figure 8</a></div><!--caption a7--><div class="caption"><p id="__p47">The rotated and cut hand image.</p></div></div></div><p id="__p23" class="p p-last">
<em>(v) Fingers and Palm Segmentation.</em> With the help of the palm 
mask, fingers and the palm can be segmented easily. The part of the hand
 that is covered by the palm mask is the palm, while the other parts of 
the hand are fingers. A segmentation result of fingers and the palm is 
shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig9/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig9" rid-ob="ob-fig9" co-legend-rid="lgnd_fig9"><span>Figure 9</span></a>.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig9" co-legend-rid="lgnd_fig9"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig9/" target="figure" rid-figpopup="fig9" rid-ob="ob-fig9"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829638243376" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.009.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.009.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_018.jpg"></div></a><div id="largeobj_idm139829638243376" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig9/" target="figure" rid-figpopup="fig9" rid-ob="ob-fig9"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig9/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig9"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig9/" target="figure" rid-figpopup="fig9" rid-ob="ob-fig9">Figure 9</a></div><!--caption a7--><div class="caption"><p id="__p48">The segmented fingers.</p></div></div></div></div><div id="sec2.4" class="sec"><h3>2.4. Fingers Recognition</h3><p id="__p24" class="p p-first">In
 the segmentation image of fingers, the labeling algorithm is applied to
 mark the regions of the fingers. In the result of the labeling method, 
the detected regions in which the number of pixels is too small is 
regarded as noisy regions and discarded. Only the regions of enough 
sizes are regarded as fingers and remain. For each remained region, that
 is, a finger, the minimal bounding box is found to enclose the finger. A
 minimal bounding box is denoted as a red rectangle in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig10/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig10" rid-ob="ob-fig10" co-legend-rid="lgnd_fig10"><span>Figure 10</span></a>. Then, the center of the minimal bounding box is used to represent the center point of the finger.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig10" co-legend-rid="lgnd_fig10"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig10/" target="figure" rid-figpopup="fig10" rid-ob="ob-fig10"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829653116528" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.010.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.010.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_007.jpg"></div></a><div id="largeobj_idm139829653116528" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig10/" target="figure" rid-figpopup="fig10" rid-ob="ob-fig10"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig10/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig10"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig10/" target="figure" rid-figpopup="fig10" rid-ob="ob-fig10">Figure 10</a></div><!--caption a7--><div class="caption"><p id="__p49">The minimal bounding box.</p></div></div></div><p id="__p25">
<em>(i) Thumb Detection and Recognition.</em> The centers of the fingers
 are lined to the palm point. Then, the degrees between these lines and 
the wrist line are computed. If there is a degree smaller than 50°, it 
means that the thumb appears in the hand image. The corresponding center
 is the center point of the thumb. The detected thumb is marked with the
 number 1. If all the degrees are larger than 50°, the thumb does not 
exist in the image.</p><p id="__p26">
<em>(ii) Detection and Recognition of Other Fingers.</em> In order to 
detect and recognize the other fingers, the palm line is first searched.
 The palm line parallels to the wrist line. The palm line is searched in
 the way: start from the row of the wrist line. For each row, a line 
paralleling to the wrist line crosses the hand. If there is only one 
connected set of white pixels in the intersection of the line and the 
hand, the line shifts upward. Once there are more than one connected 
sets of white pixels in the intersection of the line and the hand, the 
line is regarded as a candidate of the palm line. In the case of the 
thumb not detected, the line crossing the hand with more than one 
connected sets of white pixels in their intersection is chosen as the 
palm line. In the case of the thumb existing, the line continues to move
 upward with the edge points of the palm instead of the thumb as the 
starting point of the line. Now, since the thumb is taken away, there is
 only one connected set of pixels in the intersection of the line and 
the hand. Once the connected set of white pixels turns to 2 again, the 
palm line is found. The search of the palm line is shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig11/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig11" rid-ob="ob-fig11" co-legend-rid="lgnd_fig11"><span>Figure 11</span></a>.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig11" co-legend-rid="lgnd_fig11"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig11/" target="figure" rid-figpopup="fig11" rid-ob="ob-fig11"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829650594464" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.011.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.011.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_016.jpg"></div></a><div id="largeobj_idm139829650594464" class="largeobj-link align_right" style=""><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig11/" target="figure" rid-figpopup="fig11" rid-ob="ob-fig11"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig11/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig11"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig11/" target="figure" rid-figpopup="fig11" rid-ob="ob-fig11">Figure 11</a></div><!--caption a7--><div class="caption"><p id="__p50">The palm line.</p></div></div></div><p id="__p27">After
 the palm line is obtained, it is divided into 4 parts. According to the
 horizontal coordinate of the center point of a finger, it falls into 
certain parts. If the finger falls into the first part, it is the 
forefinger. If the finger belongs to the second part, it is the middle 
finger. The third part corresponds to the ring finger. The fourth part 
is the little finger. The result of finger recognition of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig3/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig3" rid-ob="ob-fig3" co-legend-rid="lgnd_fig3"><span>Figure 3</span></a> is demonstrated in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig12/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig12" rid-ob="ob-fig12" co-legend-rid="lgnd_fig12"><span>Figure 12</span></a>. In the figure, the yellow line is the palm line and the red line parallels to the wrist line.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig12" co-legend-rid="lgnd_fig12"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig12/" target="figure" rid-figpopup="fig12" rid-ob="ob-fig12"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829645567120" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.012.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.012.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_006.jpg"></div></a><div id="largeobj_idm139829645567120" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig12/" target="figure" rid-figpopup="fig12" rid-ob="ob-fig12"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig12/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig12"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig12/" target="figure" rid-figpopup="fig12" rid-ob="ob-fig12">Figure 12</a></div><!--caption a7--><div class="caption"><p id="__p51">The recognition of the fingers.</p></div></div></div><p id="__p28" class="p p-last">In
 some case, two or more fingers stay closely and there is no interval 
among the fingers. An example of the case is referred to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig18/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig18" rid-ob="ob-fig18" co-legend-rid="lgnd_fig18"><span>Figure 18</span></a>.
 In order to discriminate the case from that of a single finger, the 
width of the minimal bounding box is used as a discrimination index. If 
the width of the minimal bounding box is equal to a usual value, the 
detected region is a single finger. If the width of the minimal bounding
 box is several times of the usual value, the detected region 
corresponds to several fingers that stay together closely. For the 
robustness of finger recognition, the distances and angles between 
fingers are also taken into account to discriminate different gestures.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig18" co-legend-rid="lgnd_fig18"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig18/" target="figure" rid-figpopup="fig18" rid-ob="ob-fig18"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829648364592" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.018.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.018.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_014.jpg"></div></a><div id="largeobj_idm139829648364592" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig18/" target="figure" rid-figpopup="fig18" rid-ob="ob-fig18"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig18/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig18"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig18/" target="figure" rid-figpopup="fig18" rid-ob="ob-fig18">Figure 18</a></div><!--caption a7--><div class="caption"><p id="__p57">The recognition of the hand gesture S2.</p></div></div></div></div><div id="sec2.5" class="sec sec-last"><h3>2.5. Recognition of Hand Gestures</h3><p id="__p29" class="p p-first-last">When
 the fingers are detected and recognized, the hand gesture can be 
recognized using a simple rule classifier. In the rule classifier, the 
hand gesture is predicted according to the number and content of fingers
 detected. The content of the fingers means what fingers are detected. 
The rule classifier is very effective and efficient. For example, if 
three fingers, that is, the middle finger, the ring finger, and the 
little finger, are detected, the hand gesture is classified as the label
 3 (refer to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig13/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig13" rid-ob="ob-fig13" co-legend-rid="lgnd_fig13"><span>Figure 13</span></a> for the labels of the hand gestures).</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig13" co-legend-rid="lgnd_fig13"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig13/" target="figure" rid-figpopup="fig13" rid-ob="ob-fig13"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829652124336" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.013.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.013.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_010.jpg"></div></a><div id="largeobj_idm139829652124336" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig13/" target="figure" rid-figpopup="fig13" rid-ob="ob-fig13"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig13/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig13"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig13/" target="figure" rid-figpopup="fig13" rid-ob="ob-fig13">Figure 13</a></div><!--caption a7--><div class="caption"><p id="__p52">The
 image set of hand gestures used in the experiments. From left to right 
and then from top to bottom; these gestures are labeled as 0, 1, 2, 3, 
4, 5, 6, 7, 8, 9, S1, S2, and S3.</p></div></div></div></div></div><div id="sec3" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec3title">3. Experimental Results</h2><div id="sec3.1" class="sec sec-first"><h3>3.1. Data Sets</h3><p id="__p30" class="p p-first">In
 the experiments, two data sets of hand gestures are used to evaluate 
the performance of the proposed method. The data set 1 is an image 
collection of thirteen gestures. For each gesture, 100 images are 
captured. So, there are total 1300 images for hand gesture recognition. 
All the gesture images belong to 3 females and 4 males. The size of one 
gesture image is 640 × 480. The thirteen gestures are shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig13/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig13" rid-ob="ob-fig13" co-legend-rid="lgnd_fig13"><span>Figure 13</span></a>. From left to right and then from top to bottom, these gestures are labeled as 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, S1, S2, and S3.</p><p id="__p31" class="p p-last">Another data set [<a href="#B25" rid="B25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>]
 is collected from 10 subjects, and it contains 10 gestures for number 0
 to 9. So, there are total 10 × 10 × 10 cases. The data set captured in 
cluttered backgrounds is a great challenge for hand gesture recognition.
 Besides, for each gesture, the subject poses with variations in hand 
orientation, scale, articulation, and so forth. We compare our method 
with FEMD [<a href="#B25" rid="B25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>] on the data set.</p></div><div id="sec3.2" class="sec"><h3>3.2. Performance Evaluation on Data Set 1</h3><p id="__p32" class="p p-first">
<em>(i) Classification Accuracy.</em> In order to measure the 
performance of the proposed hand gesture recognition method, the 
classification accuracy is evaluated in the experiments. In the training
 stage, the rules discriminating the thirteen gestures are produced. 
Then, the rule classifier uses the rules to predict the identification 
of the testing image. In Figures <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig14/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig14" rid-ob="ob-fig14" co-legend-rid="lgnd_fig14"><span style="position: relative;text-decoration:none;">​<span class="figpopup-sensitive-area" style="left: -3.5em;">Figures14,</span></span><span>14</span></a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig15/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig15" rid-ob="ob-fig15" co-legend-rid="lgnd_fig15"><span style="position: relative;text-decoration:none;">​<span class="figpopup-sensitive-area" style="left: -0.5em;">,15,</span></span><span>15</span></a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig16/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig16" rid-ob="ob-fig16" co-legend-rid="lgnd_fig16"><span style="position: relative;text-decoration:none;">​<span class="figpopup-sensitive-area" style="left: -0.5em;">,16,</span></span><span>16</span></a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig17/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig17" rid-ob="ob-fig17" co-legend-rid="lgnd_fig17"><span style="position: relative;text-decoration:none;">​<span class="figpopup-sensitive-area" style="left: -0.5em;">,17,</span></span><span>17</span></a>, and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig18/" target="figure" class="fig-table-link figpopup" rid-figpopup="fig18" rid-ob="ob-fig18" co-legend-rid="lgnd_fig18"><span style="position: relative;text-decoration:none;">​<span class="figpopup-sensitive-area" style="left: -1.5em;">and18,</span></span><span>18</span></a>,
 the recognition of five gestures are demonstrated. In each figure, 
there are six subfigures which are the images showing the binary hand 
image, the palm point and wrist line, the calibrated hand image, the 
palm mask, the detected fingers, and finger and gesture recognition, 
respectively. In the subfigure of finger and gesture recognition, the 
label of the gesture is predicted. The predicted label is shown behind 
the word “Answer.”</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig14" co-legend-rid="lgnd_fig14"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig14/" target="figure" rid-figpopup="fig14" rid-ob="ob-fig14"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829651880656" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.014.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.014.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_005.jpg"></div></a><div id="largeobj_idm139829651880656" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig14/" target="figure" rid-figpopup="fig14" rid-ob="ob-fig14"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig14/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig14"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig14/" target="figure" rid-figpopup="fig14" rid-ob="ob-fig14">Figure 14</a></div><!--caption a7--><div class="caption"><p id="__p53">The recognition of the hand gesture 1.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig15" co-legend-rid="lgnd_fig15"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig15/" target="figure" rid-figpopup="fig15" rid-ob="ob-fig15"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829657269824" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.015.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.015.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_013.jpg"></div></a><div id="largeobj_idm139829657269824" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig15/" target="figure" rid-figpopup="fig15" rid-ob="ob-fig15"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig15/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig15"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig15/" target="figure" rid-figpopup="fig15" rid-ob="ob-fig15">Figure 15</a></div><!--caption a7--><div class="caption"><p id="__p54">The recognition of the hand gesture 2.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig16" co-legend-rid="lgnd_fig16"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig16/" target="figure" rid-figpopup="fig16" rid-ob="ob-fig16"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829650288736" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.016.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.016.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_002.jpg"></div></a><div id="largeobj_idm139829650288736" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig16/" target="figure" rid-figpopup="fig16" rid-ob="ob-fig16"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig16/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig16"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig16/" target="figure" rid-figpopup="fig16" rid-ob="ob-fig16">Figure 16</a></div><!--caption a7--><div class="caption"><p id="__p55">The recognition of the hand gesture 4.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="fig17" co-legend-rid="lgnd_fig17"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig17/" target="figure" rid-figpopup="fig17" rid-ob="ob-fig17"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829692094656" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.017.jpg" title="An external file that holds a picture, illustration, etc.
Object name is TSWJ2014-267872.017.jpg" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/TSWJ2014-267872_004.jpg"></div></a><div id="largeobj_idm139829692094656" class="largeobj-link align_right" style="display: none"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig17/" target="figure" rid-figpopup="fig17" rid-ob="ob-fig17"></a><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig17/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_fig17"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/figure/fig17/" target="figure" rid-figpopup="fig17" rid-ob="ob-fig17">Figure 17</a></div><!--caption a7--><div class="caption"><p id="__p56">The recognition of the hand gesture 8.</p></div></div></div><p id="__p33">The classification result of the total 1300 images is summarized with a confusion matrix in the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab1/" target="table" class="fig-table-link figpopup" rid-figpopup="tab1" rid-ob="ob-tab1" co-legend-rid=""><span>Table 1</span></a>.
 In the confusion matrix, the first column and the last row are the 
labels of the gestures. The other entries of the matrix record the 
numbers of the gesture images predicted as the corresponding labels. For
 example, for the first row, the numbers 99 and 1 are in the columns 
corresponding to the labels 1 and 3, respectively. It means that there 
are 99 and 1 images predicted as the labels 1 and 3 in the 100 testing 
images of the gesture 1. So, for the testing images of the gesture 1, 
the classification accuracy is 99%. As is shown in the confusion matrix,
 the proposed method performs well and obtains very high classification 
accuracies. The total classification accuracy of 1300 testing image is 
96.69%. In the confusion matrix, the gestures of S2 and S3 are 
misclassified as 5. The reason is described as follows: for some 
gestures of S2 and S3, the fingers do not stay closely. That is, there 
is a hole between two fingers. So, in these cases, the gestures of S2 
and S3 are misclassified as 5.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap table anchored whole_rhythm" id="tab1"><h3>Table 1</h3><!--caption a7--><div class="caption"><p id="__p59">The confusion matrix of hand gesture recognition on data set 1.</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829693621888" class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><tbody><tr><td rowspan="1" colspan="1" align="left"> 1 </td><td rowspan="1" colspan="1" align="center">99 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">94 </td><td rowspan="1" colspan="1" align="center">6 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center">95 </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 4 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center">95 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 5 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">93 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 6 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">100 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 7 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">96 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 8 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">5 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">92 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 9 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">100 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 0 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">99 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> S1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">99 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> S2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">98 </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> S3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> 97</td></tr><tr><td rowspan="1" colspan="1" align="left"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center">5 </td><td rowspan="1" colspan="1" align="center">6 </td><td rowspan="1" colspan="1" align="center">7 </td><td rowspan="1" colspan="1" align="center">8 </td><td rowspan="1" colspan="1" align="center">9 </td><td rowspan="1" colspan="1" align="center">0 </td><td rowspan="1" colspan="1" align="center">S1 </td><td rowspan="1" colspan="1" align="center">S2 </td><td rowspan="1" colspan="1" align="center">S3 </td></tr></tbody></table></div><div id="largeobj_idm139829693621888" class="largeobj-link align_right" style="display: none"><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab1/?report=objectonly">Open in a separate window</a></div></div><p id="__p34" class="p p-last">
<em>(ii) Time Cost.</em> The time cost for recognizing the gestures is reported in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab2/" target="table" class="fig-table-link figpopup" rid-figpopup="tab2" rid-ob="ob-tab2" co-legend-rid=""><span>Table 2</span></a>.
 In the table, the unit of the time cost is second. A value in the 
second row is the averaging runtime of 100 images of one gesture. For 
the total 1300 images, the averaging time cost to recognize hand 
gestures is 0.024 seconds. The experiments are run on the laptop 
computer of Intel i7-2630 2.00 GHz CPU and 4 GB RAM. It is obvious that 
the proposed method is very highly efficient and can meet the 
requirement of the real-time applications.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap table anchored whole_rhythm" id="tab2"><h3>Table 2</h3><!--caption a7--><div class="caption"><p id="__p60">The runtime of hand gesture recognition.</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829652462656" class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th rowspan="1" colspan="1" align="left"> 1 </th><th rowspan="1" colspan="1" align="center">2 </th><th rowspan="1" colspan="1" align="center">3 </th><th rowspan="1" colspan="1" align="center">4 </th><th rowspan="1" colspan="1" align="center">5 </th><th rowspan="1" colspan="1" align="center">6 </th><th rowspan="1" colspan="1" align="center">7 </th><th rowspan="1" colspan="1" align="center">8 </th><th rowspan="1" colspan="1" align="center">9 </th><th rowspan="1" colspan="1" align="center">0 </th><th rowspan="1" colspan="1" align="center">S1 </th><th rowspan="1" colspan="1" align="center">S2 </th><th rowspan="1" colspan="1" align="center">S3 </th></tr></thead><tbody><tr><td rowspan="1" colspan="1" align="left">0.024 </td><td rowspan="1" colspan="1" align="center">0.021 </td><td rowspan="1" colspan="1" align="center">0.022 </td><td rowspan="1" colspan="1" align="center">0.024 </td><td rowspan="1" colspan="1" align="center">0.027 </td><td rowspan="1" colspan="1" align="center">0.023 </td><td rowspan="1" colspan="1" align="center">0.026 </td><td rowspan="1" colspan="1" align="center">0.022 </td><td rowspan="1" colspan="1" align="center">0.025 </td><td rowspan="1" colspan="1" align="center">0.022 </td><td rowspan="1" colspan="1" align="center">0.022 </td><td rowspan="1" colspan="1" align="center">0.026 </td><td rowspan="1" colspan="1" align="center">0.021 </td></tr></tbody></table></div><div id="largeobj_idm139829652462656" class="largeobj-link align_right" style="display: none"><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab2/?report=objectonly">Open in a separate window</a></div></div></div><div id="sec3.3" class="sec sec-last"><h3>3.3. Performance Comparison on Data Set 2</h3><p id="__p35" class="p p-first-last">The
 comparison of the proposed method and a state-of-art method FEMD is 
performed on data set 2. The classification results are also summarized 
with the confusion matrixes. The description of the confusion matrixes 
is similar to that in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab1/" target="table" class="fig-table-link figpopup" rid-figpopup="tab1" rid-ob="ob-tab1" co-legend-rid=""><span>Table 1</span></a>. The confusion matrix of our method is shown in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab3/" target="table" class="fig-table-link figpopup" rid-figpopup="tab3" rid-ob="ob-tab3" co-legend-rid=""><span>Table 3</span></a>. The confusion matrix of FEMD is demonstrated in <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab4/" target="table" class="fig-table-link figpopup" rid-figpopup="tab4" rid-ob="ob-tab4" co-legend-rid=""><span>Table 4</span></a>.
 The averaging accuracy of the proposed method is 96.6%. The averaging 
accuracy of FEMD is 93.2%. The comparison results on data set 2 show 
that our method outperforms FEMD. The averaging time of our method spent
 on recognizing a hand gesture is 0.0202 seconds.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap table anchored whole_rhythm" id="tab3"><h3>Table 3</h3><!--caption a7--><div class="caption"><p id="__p61">The confusion matrix of our method on data set 2.</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829651599936" class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><tbody><tr><td rowspan="1" colspan="1" align="left"> 0 </td><td rowspan="1" colspan="1" align="center">99 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">100 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">7 </td><td rowspan="1" colspan="1" align="center">91 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1</td></tr><tr><td rowspan="1" colspan="1" align="left"> 3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">100 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 4 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">99 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 5 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">97 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 6 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">99 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 7 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">9 </td><td rowspan="1" colspan="1" align="center">88 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 8 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">7 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">93 </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 9 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">100</td></tr><tr><td rowspan="1" colspan="1" align="left"> </td><td rowspan="1" colspan="1" align="center">0 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center">5 </td><td rowspan="1" colspan="1" align="center">6 </td><td rowspan="1" colspan="1" align="center">7 </td><td rowspan="1" colspan="1" align="center">8 </td><td rowspan="1" colspan="1" align="center">9</td></tr></tbody></table></div><div id="largeobj_idm139829651599936" class="largeobj-link align_right" style="display: none"><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab3/?report=objectonly">Open in a separate window</a></div></div><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap table anchored whole_rhythm" id="tab4"><h3>Table 4</h3><!--caption a7--><div class="caption"><p id="__p62">The confusion matrix of FEMD on data set 2 (from [<a href="#B25" rid="B25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>]).</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139829654208912" class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><tbody><tr><td rowspan="1" colspan="1" align="left"> 0 </td><td rowspan="1" colspan="1" align="center">95 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 1 </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">86 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center">94 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center">87 </td><td rowspan="1" colspan="1" align="center">6 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 4 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">7 </td><td rowspan="1" colspan="1" align="center">89 </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 5 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">95 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 6 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center">96 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 7 </td><td rowspan="1" colspan="1" align="center">6 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">92 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 8 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">98 </td><td rowspan="1" colspan="1" align="center"> </td></tr><tr><td rowspan="1" colspan="1" align="left"> 9 </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center"> </td><td rowspan="1" colspan="1" align="center">100</td></tr><tr><td rowspan="1" colspan="1" align="left"> </td><td rowspan="1" colspan="1" align="center">0 </td><td rowspan="1" colspan="1" align="center">1 </td><td rowspan="1" colspan="1" align="center">2 </td><td rowspan="1" colspan="1" align="center">3 </td><td rowspan="1" colspan="1" align="center">4 </td><td rowspan="1" colspan="1" align="center">5 </td><td rowspan="1" colspan="1" align="center">6 </td><td rowspan="1" colspan="1" align="center">7 </td><td rowspan="1" colspan="1" align="center">8 </td><td rowspan="1" colspan="1" align="center">9</td></tr></tbody></table></div><div id="largeobj_idm139829654208912" class="largeobj-link align_right" style="display: none"><a target="object" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/table/tab4/?report=objectonly">Open in a separate window</a></div></div></div></div><div id="sec4" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="sec4title">4. Conclusion and Future Works</h2><p id="__p36" class="p p-first">A
 new method for hand gesture recognition is introduced in this paper. 
The hand region is detected from the background by the background 
subtraction method. Then, the palm and fingers are segmented. On the 
basis of the segmentation, the fingers in the hand image are discovered 
and recognized. The recognition of hand gestures is accomplished by a 
simple rule classifier. The performance of our method is evaluated on a 
data set of 1300 hand images. The experimental results show that our 
approach performs well and is fit for the real-time applications. 
Moreover, the proposed method outperforms the state-of-art FEMD on an 
image collection of hand gestures.</p><p id="__p37" class="p p-last">The
 performance of the proposed method highly depends on the result of hand
 detection. If there are moving objects with the color similar to that 
of the skin, the objects exist in the result of the hand detection and 
then degrade the performance of the hand gesture recognition. However, 
the machine learning algorithms can discriminate the hand from the 
background. ToF cameras provide the depth information that can improve 
the performance of hand detection. So, in future works, machine learning
 methods and ToF cameras may be used to address the complex background 
problem and improve the robustness of hand detection.</p></div><div id="idm139829655800144" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="idm139829655800144title">Acknowledgments</h2><div class="sec"><p id="__p38">This
 work is supported by the National Nature Science Foundation of China 
(Grant no. 61370174 and Grant no. 61300133) and the Fundamental Research
 Funds for the Central Universities.</p></div></div><div id="__sec1" class="tsec bk-sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="__sec1title">Conflict of Interests</h2><!--/article/back/sec/--><p id="__p39" class="p p-first-last">The authors declare that there is no conflict of interests regarding the publication of this paper.</p></div><div id="idm139829652254080" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="idm139829652254080title">References</h2><div class="ref-list-sec sec" id="reference-list"><div class="ref-cit-blk half_rhythm" id="B1">1. <span class="element-citation">Bagdanov
 AD, Del Bimbo A, Seidenari L, Usai L. Real-time hand status recognition
 from RGB-D imagery. Proceedings of the 21st International Conference on
 Pattern Recognition (ICPR '12); November 2012; pp. 2456–2459.</span></div><div class="ref-cit-blk half_rhythm" id="B2">2. <span class="element-citation">Elmezain
 M, Al-Hamadi A, Michaelis B. A robust method for hand gesture 
segmentation and recognition using forward spotting scheme in 
conditional random fields. Proceedings of the 20th International 
Conference on Pattern Recognition (ICPR '10); August 2010; pp. 
3850–3853.</span></div><div class="ref-cit-blk half_rhythm" id="B3">3. <span class="element-citation">Lee
 C-S, Chun SY, Park SW. Articulated hand configuration and rotation 
estimation using extended torus manifold embedding. Proceedings of the 
21st International Conference on Pattern Recognition (ICPR '12); 
November 2012; pp. 441–444.</span></div><div class="ref-cit-blk half_rhythm" id="B4">4. <span class="element-citation">Malgireddy
 MR, Corso JJ, Setlur S, Govindaraju V, Mandalapu D. A framework for 
hand gesture recognition and spotting using sub-gesture modeling. 
Proceedings of the 20th International Conference on Pattern Recognition 
(ICPR '10); August 2010; pp. 3780–3783.</span></div><div class="ref-cit-blk half_rhythm" id="B5">5. <span class="element-citation">Suryanarayan
 P, Subramanian A, Mandalapu D. Dynamic hand pose recognition using 
depth data. Proceedings of the 20th International Conference on Pattern 
Recognition (ICPR '10); August 2010; pp. 3105–3108.</span></div><div class="ref-cit-blk half_rhythm" id="B6">6. <span class="element-citation">Park S, Yu S, Kim J, Kim S, Lee S. 3D hand tracking using Kalman filter in depth space. <span><span class="ref-journal"><em>Eurasip Journal on Advances in Signal Processing</em>. </span>2012;<span class="ref-vol">2012</span>(1, article 36)</span></span></div><div class="ref-cit-blk half_rhythm" id="B7">7. <span class="element-citation">Raheja
 JL, Chaudhary A, Singal K. Tracking of fingertips and centers of palm 
using KINECT. Proceedings of the 2nd International Conference on 
Computational Intelligence, Modelling and Simulation (CIMSim '11); 
September 2011; pp. 248–252.</span></div><div class="ref-cit-blk half_rhythm" id="B8">8. <span class="element-citation">Wang
 Y, Yang C, Wu X, Xu S, Li H. Kinect based dynamic hand gesture 
recognition algorithm research. Proceedings of the 4th International 
Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 
'12); August 2012; pp. 274–279.</span></div><div class="ref-cit-blk half_rhythm" id="B9">9. <span class="element-citation">Panwar
 M. Hand gesture recognition based on shape parameters. Proceedings of 
the International Conference on Computing, Communication and 
Applications (ICCCA '12); February 2012; pp. 1–6.</span></div><div class="ref-cit-blk half_rhythm" id="B10">10. <span class="element-citation">Meng
 ZY, Pan J-S, Tseng K-K, Zheng W. Dominant points based hand finger 
counting for recognition under skin color extraction in hand gesture 
control system. Proceedings of the 6th International Conference on 
Genetic and Evolutionary Computing (ICGEC '12); August 2012; pp. 
364–367.</span></div><div class="ref-cit-blk half_rhythm" id="B11">11. <span class="element-citation">Harshitha
 R, Syed IA, Srivasthava S. Hci using hand gesture recognition for 
digital sand model. Proceedings of the 2nd IEEE International Conference
 on Image Information Processing (ICIIP '13); 2013; pp. 453–457.</span></div><div class="ref-cit-blk half_rhythm" id="B12">12. <span class="element-citation">Yang
 R, Sarkar S, Loeding B. Handling movement epenthesis and hand 
segmentation ambiguities in continuous sign language recognition using 
nested dynamic programming. <span><span class="ref-journal"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. </span>2010;<span class="ref-vol">32</span>(3):462–477.</span>  <span class="nowrap ref pubmed">[<a href="https://www.ncbi.nlm.nih.gov/pubmed/20075472" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord&amp;rendering-type=normal">PubMed</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="B13">13. <span class="element-citation">Zafrulla
 Z, Brashear H, Starner T, Hamilton H, Presti P. American sign language 
recognition with the kinect. Proceedings of the 13th ACM International 
Conference on Multimodal Interfaces (ICMI ’11); November 2011; pp. 
279–286.</span></div><div class="ref-cit-blk half_rhythm" id="B14">14. <span class="element-citation">Uebersax
 D, Gall J, Van den Bergh M, Van Gool L. Real-time sign language letter 
and word recognition from depth data. Proceedings of the IEEE 
International Conference on Computer Vision Workshops (ICCV '11); 
November 2011; pp. 383–390.</span></div><div class="ref-cit-blk half_rhythm" id="B15">15. <span class="element-citation">Pugeault
 N, Bowden R. Spelling it out: real-time ASL fingerspelling recognition.
 Proceedings of the IEEE International Conference on Computer Vision 
Workshops (ICCV '11); November 2011; pp. 1114–1119.</span></div><div class="ref-cit-blk half_rhythm" id="B16">16. <span class="element-citation">Wickeroth
 D, Benölken P, Lang U. Markerless gesture based interaction for design 
review scenarios. Proceedings of the 2nd International Conference on the
 Applications of Digital Information and Web Technologies (ICADIWT '09);
 August 2009; pp. 682–687.</span></div><div class="ref-cit-blk half_rhythm" id="B17">17. <span class="element-citation">Frati
 V, Prattichizzo D. Using Kinect for hand tracking and rendering in 
wearable haptics. Proceedings of the IEEE World Haptics Conference (WHC 
'11); June 2011; pp. 317–321.</span></div><div class="ref-cit-blk half_rhythm" id="B18">18. <span class="element-citation">Choi
 J, Park H, Park J-I. Hand shape recognition using distance transform 
and shape decomposition. Proceedings of the 18th IEEE International 
Conference on Image Processing (ICIP '11); September 2011; pp. 
3605–3608.</span></div><div class="ref-cit-blk half_rhythm" id="B19">19. <span class="element-citation">Tan
 T-D, Guo Z-M. Research of hand positioning and gesture recognition 
based on binocular vision. Proceedings of the IEEE International 
Symposium on Virtual Reality Innovations (ISVRI '11); March 2011; pp. 
311–315.</span></div><div class="ref-cit-blk half_rhythm" id="B20">20. <span class="element-citation">Zeng
 J, Sun Y, Wang F. A natural hand gesture system for intelligent 
human-computer interaction and medical assistance. Proceedings of the 
3rd Global Congress on Intelligent Systems (GCIS '12); November 2012; 
pp. 382–385.</span></div><div class="ref-cit-blk half_rhythm" id="B21">21. <span class="element-citation">Droeschel
 D, Stückler J, Behnke S. Learning to interpret pointing gestures with a
 time-of-flight camera. Proceedings of the 6th ACM/IEEE International 
Conference on Human-Robot Interaction (HRI '11); March 2011; pp. 
481–488.</span></div><div class="ref-cit-blk half_rhythm" id="B22">22. <span class="element-citation">Hu
 K, Canavan S, Yin L. Hand pointing estimation for human computer 
interaction based on two orthogonal-views. Proceedings of the 20th 
International Conference on Pattern Recognition (ICPR '10); August 2010;
 pp. 3760–3763.</span></div><div class="ref-cit-blk half_rhythm" id="B23">23. <span class="element-citation">Shimada
 A, Yamashita T, Taniguchi R-I. Hand gesture based TV control 
system—towards both user—&amp; machine-friendly gesture applications. 
Proceedings of the 19th Korea-Japan Joint Workshop on Frontiers of 
Computer Vision (FCV '13); February 2013; pp. 121–126.</span></div><div class="ref-cit-blk half_rhythm" id="B24">24. <span class="element-citation">Keskin
 C, Kiraç F, Kara YE, Akarun L. Real time hand pose estimation using 
depth sensors. Proceedings of the IEEE International Conference on 
Computer Vision Workshops (ICCV '11); November 2011; pp. 1228–1234.</span></div><div class="ref-cit-blk half_rhythm" id="B25">25. <span class="element-citation">Ren Z, Yuan J, Meng J, Zhang Z. Robust part-based hand gesture recognition using kinect sensor. <span><span class="ref-journal"><em>IEEE Transactions on Multimedia</em>. </span>2013;<span class="ref-vol">15</span>(5):1110–1120.</span></span></div><div class="ref-cit-blk half_rhythm" id="B26">26. <span class="element-citation">Mo
 Z, Neumann U. Real-time hand pose recognition using low-resolution 
depth images. Proceedings of the IEEE Computer Society Conference on 
Computer Vision and Pattern Recognition (CVPR '06); June 2006; pp. 
1499–1505.</span></div><div class="ref-cit-blk half_rhythm" id="B27">27. <span class="element-citation">Miyamoto
 S, Matsuo T, Shimada N, Shirai Y. Real-time and precise 3-D hand 
posture estimation based on classification tree trained with variations 
of appearances. Proceedings of the 21st International Conference on 
Pattern Recognition (ICPR '12); November 2012; pp. 453–456.</span></div><div class="ref-cit-blk half_rhythm" id="B28">28. <span class="element-citation">Li
 C, Kitani KM. Pixel-level hand detection in egocentric videos. 
Proceedings of the IEEE Conference on Computer Vision and Pattern 
Recognition (CVPR '13); 2013; pp. 3570–3577.</span></div><div class="ref-cit-blk half_rhythm" id="B29">29. <span class="element-citation">Dewaele G, Devernay F, Horaud R.  <span class="ref-journal"><em>Computer Vision—ECCV 2004</em>.</span>
 Vol. 3021. Springer; 2004. Hand motion from 3d point trajectories and a
 smooth surface model; pp. 495–507. (Lecture Notes in Computer Science).</span></div></div></div><div style="display: none; width: 200px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbilinksmenu"><ul id="ui-ncbiinpagenav-2"><li><a href="#idm139829647637120title">Abstract</a></li><li><a href="#sec1title">1. Introduction</a></li><li><a href="#sec2title">2. The Proposed Method for Hand Gesture Recognition</a></li><li><a href="#sec3title">3. Experimental Results</a></li><li><a href="#sec4title">4. Conclusion and Future Works</a></li><li><a href="#idm139829655800144title">Acknowledgments</a></li><li><a href="#__sec1title">Conflict of Interests</a></li><li><a href="#idm139829652254080title">References</a></li></ul></div></div><!--post-content--><div class="courtesy-note whole_rhythm small"><hr>Articles from <span class="acknowledgment-journal-title">The Scientific World Journal</span> are provided here courtesy of <strong>Hindawi Limited</strong></div></div>
            
            
        
            
        </div>
        <!-- Book content -->
    </div>
    
    <div id="rightcolumn" class="four_col col last">
        <!-- Custom content above discovery portlets -->
        <div class="col6">
            
        </div>
        
        <div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><div class="format-menu"><h2>Formats:</h2><ul><li class="selected">Article</li> | <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/?report=reader">PubReader</a></li> | <li class="epub-link"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/epub/">ePub (beta)</a></li> | <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4099175/pdf/TSWJ2014-267872.pdf">PDF (1.6M)</a></li> | <li><a href="#" data-citationid="PMC4099175" class="citationexporter ctxp" role="button" aria-expanded="false" aria-haspopup="true">Citation</a></li></ul></div></div><div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="share-buttons"><h2>Share</h2><ul><li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4099175%2F" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><img src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/4047626.png" alt="Share on Facebook">
                             Facebook
                        </a></li><li class="twitter"><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4099175%2F&amp;text=Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><img src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/4047627.png" alt="Share on Twitter">
                             Twitter
                        </a></li><li class="gplus"><a href="https://plus.google.com/share?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4099175%2F" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><img src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/4047628.png" alt="Share on Google Plus">
                             Google+
                        </a></li></ul></div>
        
        <div id="ajax-portlets" data-pmid="25054171" data-aiid="4099175" data-aid="4099175" data-iid="233213" data-domainid="1623" data-domain="tswj" data-accid="PMC4099175" data-md5="9c616d8a2a89a91e8d64ef49f668aa4b">
<div class="portlet pubmed_favoritesad">
<div class="portlet_head">
<div class="portlet_title"><h3><span>Save items</span></h3></div>
<a name="Shutter" sid="1" href="#" class="portlet_shutter ui-ncbitoggler-open" title="Show/hide content" remembercollapsed="true" pgsec_name="pmfavad" toggles="ui-portlet_content-4" role="button" aria-expanded="true" style="position: absolute; padding: 0px;"></a>
</div>
<div class="ui-helper-reset" aria-live="assertive"><div class="portlet_content ui-ncbitoggler ui-ncbitoggler-slave-open" id="ui-portlet_content-4" aria-hidden="false"><div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
<input name="absid" id="absid" value="4099175" type="hidden"><div id="pubmed_favoritesad" class="empty" data-db="pmc">
<span role="menubar"><div class="ui-ncbisetswitch ltd-hover" role="menuitem" aria-expanded="false" aria-haspopup="true"><a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/" class="jig-ncbisetswitch blind collink ltd-hover ui-ncbisetswitch-hasStar" id="favList" data-jigconfig="destSelector:'#favUL',starExists:true,createCollectionUrl:'#',manageCollectionsUrl:'/myncbi/collections/'"><span class="star"></span>Add to Favorites</a><a class="ui-ncbisetswitch-button ltd-hover" title="View more options" href="#"><span class="ui-icon ui-icon-triangle-1-s ui-ncbisetswitch-down">View more options</span></a></div></span><div style="display: none; width: 200px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbilinksmenu ui-ncbisetswitch-popper"><ul id="favUL" class="ui-ncbisetswitch-options"></ul><ul class="ui-ncbisetswitch-actions"><li class="ui-ncbisetswitch-actions-create" style="display: block;"><a class="ui-ncbisetswitch-create-collection" href="#">Create collection...</a></li><li class="ui-ncbisetswitch-actions-manage" style="display: block;"><a class="ui-ncbisetswitch-manage-collections" href="https://www.ncbi.nlm.nih.gov/myncbi/collections/">Manage collections...</a></li></ul></div>
</div>
<div class="colloading">loading</div>
<span id="submenu_AddToCollections"><form method="post"><input class="button_apply" name="addtocollection" value="1" type="submit"></form></span>
</div></div></div>
</div><div class="portlet">
<div class="portlet_head">
<div class="portlet_title"><h3><span>Similar articles in PubMed</span></h3></div>
<a name="Shutter" sid="1" href="#" class="portlet_shutter ui-ncbitoggler-open" title="Show/hide content" remembercollapsed="true" pgsec_name="PBooksDiscovery_RA" toggles="ui-portlet_content-5" role="button" aria-expanded="true" style="position: absolute; padding: 0px;"></a>
</div>
<div class="ui-helper-reset" aria-live="assertive"><div class="portlet_content ui-ncbitoggler ui-ncbitoggler-slave-open" id="ui-portlet_content-5" aria-hidden="false">
<ul>
<li class="brieflinkpopper two_line">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pubmed/19574627" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">A unified framework for gesture recognition and spatiotemporal gesture segmentation.</a><span class="source">[IEEE Trans Pattern Anal Mach I...]</span><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-6" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">
<em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="author">Alon J, Athitsos V, Yuan Q, Sclaroff S. </em><em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="cit">IEEE Trans Pattern Anal Mach Intell. 2009 Sep; 31(9):1685-99. </em>
</div>
</li>
<li class="brieflinkpopper two_line">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pubmed/26016921" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">Real-time human pose estimation and gesture recognition from depth images using superpixels and SVM classifier.</a><span class="source">[Sensors (Basel). 2015]</span><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-7" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">
<em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="author">Kim H, Lee S, Lee D, Choi S, Ju J, Myung H. </em><em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="cit">Sensors (Basel). 2015 May 26; 15(6):12410-27. Epub 2015 May 26.</em>
</div>
</li>
<li class="brieflinkpopper two_line">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pubmed/25258732" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">Method for user interface of large displays using arm pointing and finger counting gesture recognition.</a><span class="source">[ScientificWorldJournal. 2014]</span><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-8" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">
<em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="author">Kim H, Kim Y, Lee EC. </em><em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="cit">ScientificWorldJournal. 2014; 2014:683045. Epub 2014 Sep 1.</em>
</div>
</li>
<li class="brieflinkpopper two_line">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pubmed/24991650" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">An adaptive superpixel based hand gesture tracking and recognition system.</a><span class="source">[ScientificWorldJournal. 2014]</span><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-9" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">
<em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="author">Zhu HM, Pun CM. </em><em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="cit">ScientificWorldJournal. 2014; 2014:849069. Epub 2014 May 27.</em>
</div>
</li>
<li class="brieflinkpopper two_line">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pubmed/26731641" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">Explore Efficient Local Features from RGB-D Data for One-Shot Learning Gesture Recognition.</a><span class="source">[IEEE Trans Pattern Anal Mach I...]</span><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-10" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">
<em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="author">Wan J, Guo G, Li SZ. </em><em xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="cit">IEEE Trans Pattern Anal Mach Intell. 2016 Aug; 38(8):1626-39. Epub 2015 Dec 30.</em>
</div>
</li>
</ul>
<a class="seemore" href="https://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;cmd=link&amp;linkname=pubmed_pubmed_reviews&amp;uid=25054171&amp;log%24=relatedreviews&amp;logdbfrom=pmc" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Reviews&amp;rendering-type=normal">See reviews...</a><a class="seemore" href="https://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&amp;cmd=link&amp;linkname=pubmed_pubmed&amp;uid=25054171&amp;log%24=relatedarticles&amp;logdbfrom=pmc" ref="reftype=relart&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|RelatedArticles&amp;TO=Entrez|Pubmed|Related%20Records&amp;rendering-type=normal">See all...</a>
</div></div>
</div><div class="portlet">
<div class="portlet_head">
<div class="portlet_title"><h3><span>Links</span></h3></div>
<a name="Shutter" sid="1" href="#" class="portlet_shutter ui-ncbitoggler-open" title="Show/hide content" remembercollapsed="true" pgsec_name="PMCVCitedByPmcArticlesP" toggles="ui-portlet_content-11" role="button" aria-expanded="true" style="position: absolute; padding: 0px;"></a>
</div>
<div class="ui-helper-reset" aria-live="assertive"><div class="portlet_content ui-ncbitoggler ui-ncbitoggler-slave-open" id="ui-portlet_content-11" aria-hidden="false"><ul>
<li class="brieflinkpopper">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pubmed/25054171/" ref="reftype=PubMed&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|DiscoveryLinks&amp;TO=Entrez|PubMed|Record&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">PubMed</a><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-12" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">PubMed<div class="brieflinkpopdesc">PubMed citations for these articles</div>
</div>
</li>
<li class="brieflinkpopper">
<a class="brieflinkpopperctrl" href="https://www.ncbi.nlm.nih.gov/pmc/?Db=taxonomy&amp;DbFrom=pmc&amp;Cmd=Link&amp;LinkName=pmc_taxonomy&amp;IdsFromResult=4099175" ref="reftype=Taxonomy&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|DiscoveryLinks&amp;TO=Entrez|Crosslink|Taxonomy&amp;rendering-type=normal" role="button" aria-expanded="false" aria-haspopup="true">Taxonomy</a><div class="brieflinkpop ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" id="ui-brieflinkpop-13" aria-live="assertive" aria-hidden="true" style="top: -100px; left: -100px; display: none;">Taxonomy<div class="brieflinkpopdesc">Related taxonomy entry</div>
</div>
</li>
</ul></div></div>
</div><div class="portlet">
<div class="portlet_head">
<div class="portlet_title"><h3><span>Recent Activity</span></h3></div>
<a name="Shutter" sid="1" href="#" class="portlet_shutter shutter_closed ui-ncbitoggler" title="Show/hide content" remembercollapsed="true" pgsec_name="recent_activity" toggles="ui-portlet_content-14" role="button" aria-expanded="false" style="position: absolute; padding: 0px;"></a>
</div>
<div class="ui-helper-reset" aria-live="assertive"><div class="portlet_content ui-ncbitoggler ui-ncbitoggler-slave" style="display: none;" id="ui-portlet_content-14" aria-hidden="true"><div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" id="HTDisplay" class="">
<div class="action">
<a href="javascript:historyDisplayState('ClearHT')">Clear</a><a href="javascript:historyDisplayState('HTOff')" class="HTOn">Turn Off</a><a href="javascript:historyDisplayState('HTOn')" class="HTOff">Turn On</a>
</div>
<ul id="activity"><li class="ra_rcd ralinkpopper two_line">
<a class="htb ralinkpopperctrl" ref="log$=activity&amp;linkpos=1" href="https://www.ncbi.nlm.nih.gov/portal/utils/pageresolver.fcgi?recordid=5bc607ecdde089426b610e2b">Real-Time Hand Gesture Recognition Using Finger Segmentation</a><div class="ralinkpop offscreen_noflow">Real-Time Hand Gesture Recognition Using Finger Segmentation<div class="brieflinkpopdesc">The Scientific World Journal. 2014; 2014()</div>
</div>
<div class="tertiary"></div>
</li></ul>
<p class="HTOn">Your browsing activity is empty.</p>
<p class="HTOff">Activity recording is turned off.</p>
<p id="turnOn" class="HTOff"><a href="javascript:historyDisplayState('HTOn')">Turn recording back on</a></p>
<a class="seemore" href="https://www.ncbi.nlm.nih.gov/sites/myncbi/recentactivity">See more...</a>
</div></div></div>
</div>
<div>
<div class="portlet brieflink pmc_para_cit" id="crb--__p4" name="crb--__p4" rid="__p4" style="position: absolute; visibility: visible; width: 370px; top: 757px; display: none;">
<div class="portlet_head"></div>
<div class="portlet_content" id="ui-portlet_content-15"><ul><li class="two_line" reference_id="B12">
<a href="https://www.ncbi.nlm.nih.gov/pubmed/20075472/" ref="reftype=pubmed&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|CitedRefBlock&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal">Handling
 movement epenthesis and hand segmentation ambiguities in continuous 
sign language recognition using nested dynamic programming.</a><span class="one_line_source">[IEEE Trans Pattern Anal Mach Intell.  2010]</span><div class="alt-note">
<div class="authors">Yang R, Sarkar S, Loeding B</div>
<div class="citation">IEEE Trans Pattern Anal Mach Intell. 2010 Mar; 32(3):462-77.</div>
</div>
</li></ul></div>
</div>
<div class="portlet brieflink pmc_para_cit" id="crb--__p5" name="crb--__p5" rid="__p5" style="position: absolute; visibility: visible; width: 370px; top: 988px;">
<div class="portlet_head"></div>
<div class="portlet_content" id="ui-portlet_content-16"><ul><li class="two_line" reference_id="B12">
<a href="https://www.ncbi.nlm.nih.gov/pubmed/20075472/" ref="reftype=pubmed&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|CitedRefBlock&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal">Handling
 movement epenthesis and hand segmentation ambiguities in continuous 
sign language recognition using nested dynamic programming.</a><span class="one_line_source">[IEEE Trans Pattern Anal Mach Intell.  2010]</span><div class="alt-note">
<div class="authors">Yang R, Sarkar S, Loeding B</div>
<div class="citation">IEEE Trans Pattern Anal Mach Intell. 2010 Mar; 32(3):462-77.</div>
</div>
</li></ul></div>
</div>
</div>   
    </div>
                
        <!-- Custom content below discovery portlets -->
        <div class="col7">
            
        </div>
    </div>
</div>

<!-- Custom content after all -->
<div class="col8">
    
</div>
<div class="col9">
    
</div>

<script src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/jquery_002.js"></script>
<script>
    (function($){
        $('.skiplink').each(function(i, item){
            var href = $($(item).attr('href'));
            href.attr('tabindex', '-1').addClass('skiptarget'); // ensure the target can receive focus
            $(item).on('click', function(event){
                event.preventDefault();
                $.scrollTo(href, 0, {
                    onAfter: function(){
                        href.focus();
                    }
                });
            });
        });
    })(jQuery);
</script>



<div id="body-link-poppers"><div id="body-link-popper-B1" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">1. <span class="element-citation">Bagdanov
 AD, Del Bimbo A, Seidenari L, Usai L. Real-time hand status recognition
 from RGB-D imagery. Proceedings of the 21st International Conference on
 Pattern Recognition (ICPR '12); November 2012; pp. 2456–2459.</span> [<a href="#B1">Ref list</a>]</div><div id="body-link-popper-B4" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">4. <span class="element-citation">Malgireddy
 MR, Corso JJ, Setlur S, Govindaraju V, Mandalapu D. A framework for 
hand gesture recognition and spotting using sub-gesture modeling. 
Proceedings of the 20th International Conference on Pattern Recognition 
(ICPR '10); August 2010; pp. 3780–3783.</span> [<a href="#B4">Ref list</a>]</div><div id="body-link-popper-B5" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">5. <span class="element-citation">Suryanarayan
 P, Subramanian A, Mandalapu D. Dynamic hand pose recognition using 
depth data. Proceedings of the 20th International Conference on Pattern 
Recognition (ICPR '10); August 2010; pp. 3105–3108.</span> [<a href="#B5">Ref list</a>]</div><div id="body-link-popper-B8" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">8. <span class="element-citation">Wang
 Y, Yang C, Wu X, Xu S, Li H. Kinect based dynamic hand gesture 
recognition algorithm research. Proceedings of the 4th International 
Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 
'12); August 2012; pp. 274–279.</span> [<a href="#B8">Ref list</a>]</div><div id="body-link-popper-B9" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">9. <span class="element-citation">Panwar
 M. Hand gesture recognition based on shape parameters. Proceedings of 
the International Conference on Computing, Communication and 
Applications (ICCCA '12); February 2012; pp. 1–6.</span> [<a href="#B9">Ref list</a>]</div><div id="body-link-popper-B11" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">11. <span class="element-citation">Harshitha
 R, Syed IA, Srivasthava S. Hci using hand gesture recognition for 
digital sand model. Proceedings of the 2nd IEEE International Conference
 on Image Information Processing (ICIIP '13); 2013; pp. 453–457.</span> [<a href="#B11">Ref list</a>]</div><div id="body-link-popper-B12" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">Handling
 movement epenthesis and hand segmentation ambiguities in continuous 
sign language recognition using nested dynamic programming.<div class="authors">Yang R, Sarkar S, Loeding B</div><div class="citation">IEEE Trans Pattern Anal Mach Intell. 2010 Mar; 32(3):462-77.</div><p>[<a href="https://www.ncbi.nlm.nih.gov/pubmed/20075472/" ref="reftype=pubmed&amp;article-id=4099175&amp;issue-id=233213&amp;journal-id=1623&amp;FROM=Article|CitedRefBlock&amp;TO=Entrez|Pubmed|Record&amp;rendering-type=normal">PubMed</a>] [<a href="#B12">Ref list</a>]</p></div><div id="body-link-popper-B15" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">15. <span class="element-citation">Pugeault
 N, Bowden R. Spelling it out: real-time ASL fingerspelling recognition.
 Proceedings of the IEEE International Conference on Computer Vision 
Workshops (ICCV '11); November 2011; pp. 1114–1119.</span> [<a href="#B15">Ref list</a>]</div><div id="body-link-popper-B16" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">16. <span class="element-citation">Wickeroth
 D, Benölken P, Lang U. Markerless gesture based interaction for design 
review scenarios. Proceedings of the 2nd International Conference on the
 Applications of Digital Information and Web Technologies (ICADIWT '09);
 August 2009; pp. 682–687.</span> [<a href="#B16">Ref list</a>]</div><div id="body-link-popper-B19" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">19. <span class="element-citation">Tan
 T-D, Guo Z-M. Research of hand positioning and gesture recognition 
based on binocular vision. Proceedings of the IEEE International 
Symposium on Virtual Reality Innovations (ISVRI '11); March 2011; pp. 
311–315.</span> [<a href="#B19">Ref list</a>]</div><div id="body-link-popper-B20" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">20. <span class="element-citation">Zeng
 J, Sun Y, Wang F. A natural hand gesture system for intelligent 
human-computer interaction and medical assistance. Proceedings of the 
3rd Global Congress on Intelligent Systems (GCIS '12); November 2012; 
pp. 382–385.</span> [<a href="#B20">Ref list</a>]</div><div id="body-link-popper-B21" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">21. <span class="element-citation">Droeschel
 D, Stückler J, Behnke S. Learning to interpret pointing gestures with a
 time-of-flight camera. Proceedings of the 6th ACM/IEEE International 
Conference on Human-Robot Interaction (HRI '11); March 2011; pp. 
481–488.</span> [<a href="#B21">Ref list</a>]</div><div id="body-link-popper-B22" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">22. <span class="element-citation">Hu
 K, Canavan S, Yin L. Hand pointing estimation for human computer 
interaction based on two orthogonal-views. Proceedings of the 20th 
International Conference on Pattern Recognition (ICPR '10); August 2010;
 pp. 3760–3763.</span> [<a href="#B22">Ref list</a>]</div><div id="body-link-popper-B13" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">13. <span class="element-citation">Zafrulla
 Z, Brashear H, Starner T, Hamilton H, Presti P. American sign language 
recognition with the kinect. Proceedings of the 13th ACM International 
Conference on Multimodal Interfaces (ICMI ’11); November 2011; pp. 
279–286.</span> [<a href="#B13">Ref list</a>]</div><div id="body-link-popper-B23" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">23. <span class="element-citation">Shimada
 A, Yamashita T, Taniguchi R-I. Hand gesture based TV control 
system—towards both user—&amp; machine-friendly gesture applications. 
Proceedings of the 19th Korea-Japan Joint Workshop on Frontiers of 
Computer Vision (FCV '13); February 2013; pp. 121–126.</span> [<a href="#B23">Ref list</a>]</div><div id="body-link-popper-B24" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">24. <span class="element-citation">Keskin
 C, Kiraç F, Kara YE, Akarun L. Real time hand pose estimation using 
depth sensors. Proceedings of the IEEE International Conference on 
Computer Vision Workshops (ICCV '11); November 2011; pp. 1228–1234.</span> [<a href="#B24">Ref list</a>]</div><div id="body-link-popper-B25" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">25. <span class="element-citation">Ren Z, Yuan J, Meng J, Zhang Z. Robust part-based hand gesture recognition using kinect sensor. <span><span class="ref-journal"><em>IEEE Transactions on Multimedia</em>. </span>2013;<span class="ref-vol">15</span>(5):1110–1120.</span></span> [<a href="#B25">Ref list</a>]</div><div id="body-link-popper-B27" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">27. <span class="element-citation">Miyamoto
 S, Matsuo T, Shimada N, Shirai Y. Real-time and precise 3-D hand 
posture estimation based on classification tree trained with variations 
of appearances. Proceedings of the 21st International Conference on 
Pattern Recognition (ICPR '12); November 2012; pp. 453–456.</span> [<a href="#B27">Ref list</a>]</div><div id="body-link-popper-B28" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">28. <span class="element-citation">Li
 C, Kitani KM. Pixel-level hand detection in egocentric videos. 
Proceedings of the IEEE Conference on Computer Vision and Pattern 
Recognition (CVPR '13); 2013; pp. 3570–3577.</span> [<a href="#B28">Ref list</a>]</div><div id="body-link-popper-B29" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 30em; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">29. <span class="element-citation">Dewaele G, Devernay F, Horaud R.  <span class="ref-journal"><em>Computer Vision—ECCV 2004</em>.</span>
 Vol. 3021. Springer; 2004. Hand motion from 3d point trajectories and a
 smooth surface model; pp. 495–507. (Lecture Notes in Computer Science).</span> [<a href="#B29">Ref list</a>]</div></div>
                        </div>
                        <div class="bottom">
                            
                            <div id="NCBIFooter_dynamic">
    <a id="help-desk-link" class="help_desk" href="" target="_blank">Support Center</a>
    <a id="help-desk-link" class="help_desk" href="https://support.ncbi.nlm.nih.gov/ics/support/KBList.asp?Time=2018-10-16T11:46:52-04:00&amp;Snapshot=%2Fprojects%2FPMC%2FPMCViewer@4.46&amp;Host=ptpmc201&amp;ncbi_phid=F4FB45D7BC6073510000000000C400BE&amp;ncbi_session=8A1A6BE9BC607391_0159SID&amp;from=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4099175%2F&amp;Db=pmc&amp;folderID=132&amp;Ncbi_App=pmc&amp;Page=literature&amp;style=classic&amp;deptID=28049" target="_blank">Support Center</a>
    
</div>

                            <div class="footer" id="footer">
    
    <div class="subfooter"> </div><script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/preloaderWidget.js"> </script>
    <div id="external-disclaimer" class="offscreen_noflow">
        External link. Please review our <a href="https://www.nlm.nih.gov/privacy.html">privacy policy</a>.
    </div>    
    <div id="ncbifooter" class="contact_info">      
        <div id="footer-contents-right">
            <div id="nlm_thumb_logo">
                <a href="https://www.nlm.nih.gov/" title="NLM">NLM</a>
            </div>
            <div id="nih_thumb_logo">
                <a href="https://www.nih.gov/" title="NIH">NIH</a>
            </div>
            <div id="hhs_thumb_logo">
                <a href="https://www.hhs.gov/" title="DHHS">DHHS</a>
            </div>
            <div id="usagov_thumb_logo">
                <a href="https://www.usa.gov/" title="USA.gov">USA.gov</a>
            </div>         
        </div>
        
        <div id="footer-contents-left">
            <p class="address vcard">
                <span class="url">
                    <a class="fn url newdomain" href="https://www.ncbi.nlm.nih.gov/">National Center for
                        Biotechnology Information</a>,
                </span> <span class="org url newdomain"><a href="https://www.nlm.nih.gov/">U.S. National Library of Medicine</a></span>
                <span class="adr">
                    <span class="street-address">8600 Rockville Pike</span>, <span class="locality">Bethesda</span>
                    <span class="region">MD</span>, <span class="postal-code">20894</span>
                    <span class="country-name">USA</span>
                </span>
            </p>
            
            <a href="https://www.ncbi.nlm.nih.gov/home/about/policies.shtml">Policies and Guidelines</a> | <a href="https://www.ncbi.nlm.nih.gov/home/about/contact.shtml">Contact</a>
        </div>
    </div>
    <script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/InstrumentPageStarterJS.js"> </script>    
    <script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/hfjs2.js"> </script>
</div>
                        </div>
                    </div>
                    <!--/.page-->
                </div>
                <!--/.wrap-->
            </div><!-- /.twelve_col -->
        <div class="ui-ncbiautocomplete-holder shadow ui-ncbiautocomplete-holder-clearfix" aria-live="assertive" style="display: none; top: 66.6px; left: 344.7px; width: 670px; z-index: 1001;"><ul class="ui-ncbiautocomplete-options" role="listbox" aria-activedescendant="term"></ul><div class="ui-ncbiautocomplete-actions shadow" style="display: block;"><a class="ui-ncbiautocomplete-link-pref" style="display: none;">Preferences</a><a href="#" class="ui-ncbiautocomplete-link-off ui-ncbiautocomplete-link-pref-right" style="display: block;">Turn off</a></div></div><div style="display: none; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic">External link. Please review our <a href="https://www.nlm.nih.gov/privacy.html">privacy policy</a>.</div></div>
        <!-- /.grid -->

        <span class="PAFAppResources"></span>
        
        <!-- BESelector tab -->
        
        
        
        <noscript><img alt="statistics" src="/stat?jsdisabled=true&amp;ncbi_db=pmc&amp;ncbi_pdid=article&amp;ncbi_acc=&amp;ncbi_domain=tswj&amp;ncbi_report=record&amp;ncbi_type=fulltext&amp;ncbi_objectid=&amp;ncbi_pcid=/articles/PMC4099175/&amp;ncbi_app=pmc" /></noscript>
        
        
        <!-- usually for JS scripts at page bottom -->
        <!--<component id="PageFixtures" label="styles"></component>-->
    

<!-- 8A1A6BE9BC607391_0159SID /projects/PMC/PMCViewer@4.46 ptpmc201 v4.1.r563004 Tue, May 01 2018 03:01:28 -->

<script type="text/javascript" src="Real-Time%20Hand%20Gesture%20Recognition%20Using%20Finger%20Segmentation_files/4065628.js" snapshot="pmc"></script>
<div class="ui-dialog ui-widget ui-widget-content ui-corner-all ui-front" style="display: none;" tabindex="-1" role="dialog" aria-describedby="epubDialog" aria-labelledby="ui-id-1"><div class="ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix"><span id="ui-id-1" class="ui-dialog-title">Making articles easier to read in PMC</span><button type="button" class="ui-button ui-widget ui-state-default ui-corner-all ui-button-icon-only ui-dialog-titlebar-close" role="button" title="Close"><span class="ui-button-icon-primary ui-icon ui-icon-closethick"></span><span class="ui-button-text">Close</span></button></div><div id="epubDialog" style="display: block;" class="ui-dialog-content ui-widget-content">  <p>We
 are experimenting with display styles that make it easier to read 
articles     in PMC.     Our first effort uses eBook readers, which have
 several "ease of reading"     features already built in.</p>  <p>These PMC articles are best viewed in the <em>iBooks     reader</em>. You may notice problems with the display of certain parts of an article     in other eReaders.</p>  <div class="ui-dialog-buttonpane ui-widget-content ui-helper-clearfix"><button id="cancelEpub" class="ui-state-default ui-corner-all">Cancel</button><button id="downloadEpub" style="float: left" class="ui-state-default ui-corner-all">Download article</button></div>          </div></div><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px none; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px none; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-size-adjust: none; font-family: STIXSizeOneSym, sans-serif;"></div></div></body></html>